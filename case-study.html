<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-case-study">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.0">
<title data-rh="true">Case Study | Seamless</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://seamless-cicd.github.io/case-study"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Case Study | Seamless"><meta data-rh="true" name="description" content="1. Introduction"><meta data-rh="true" property="og:description" content="1. Introduction"><link data-rh="true" rel="icon" href="/img/seamless.png"><link data-rh="true" rel="canonical" href="https://seamless-cicd.github.io/case-study"><link data-rh="true" rel="alternate" href="https://seamless-cicd.github.io/case-study" hreflang="en"><link data-rh="true" rel="alternate" href="https://seamless-cicd.github.io/case-study" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.c2612351.css">
<link rel="preload" href="/assets/js/runtime~main.90f7624f.js" as="script">
<link rel="preload" href="/assets/js/main.350b6334.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(e){}return e}()||function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,e("light"))}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/seamless-logo-with-text.svg" alt="Seamless CI/CD" class="themedImage_ToTc themedImage--light_HNdA" width="130"><img src="/img/seamless-logo-with-text-dark.svg" alt="Seamless CI/CD" class="themedImage_ToTc themedImage--dark_i4oU" width="130"></div></a></div><div class="navbar__items navbar__items--right"><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/case-study">Case Study</a><a class="navbar__item navbar__link" href="/presentation">Presentation</a><a class="navbar__item navbar__link" href="/the-team">The Team</a><a class="navbar__item navbar__link" href="/api/pipelines">API</a><a href="https://github.com/seamless-cicd" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><main class="docMainContainer_gTbr docMainContainerEnhanced_Uz_u"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Case Study</h1><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="1-introduction">1. Introduction<a href="#1-introduction" class="hash-link" aria-label="Direct link to 1. Introduction" title="Direct link to 1. Introduction">​</a></h2><p>Software engineering teams strive to integrate and deliver code changes quickly while keeping code high-quality and bug-free. To achieve this, many members of the software engineering community have embraced a philosophy and practice called CI/CD (continuous integration and delivery). CI/CD automates processes such as building and testing code, merging it into a shared repository, packaging it into a deployable artifact, and delivering it to production. As the application moves through these phases, confidence that it can safely be released into production grows.</p><p>Microservice architectures, however, present unique testing and deployment challenges. Unlike a single application with a single deployment pipeline, microservice architectures use individual deployment pipelines for individual services. Additionally, microservices must function properly within the context of the entire system before they are deployed to production. Adequate testing must be implemented to address these complexities.</p><p>This case study describes how we built <strong>Seamless</strong>, a self-hosted, open-source, cloud-native CI/CD solution tailored for microservices. Seamless offers a low-configuration platform for automating the testing, building, and deployment of containerized microservice applications.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="2-evolution-of-deployment-processes">2. Evolution of Deployment Processes<a href="#2-evolution-of-deployment-processes" class="hash-link" aria-label="Direct link to 2. Evolution of Deployment Processes" title="Direct link to 2. Evolution of Deployment Processes">​</a></h2><p>A deployment process is a sequence of steps for building, testing, and deploying software. Before running the deployment process, it is crucial to identify the source of the code that will be used. This is where version control systems come into play.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="21-version-control-systems">2.1 Version Control Systems<a href="#21-version-control-systems" class="hash-link" aria-label="Direct link to 2.1 Version Control Systems" title="Direct link to 2.1 Version Control Systems">​</a></h3><p>Version control systems such as Git enable developers to track changes, collaborate, and revert to previous versions of code.<sup id="fnref-1"><a href="#fn-1" class="footnote-ref">1</a></sup> By creating branches, developers can isolate changes and work on new features independently, which are eventually merged into a central branch, commonly referred to as the main or master branch. This branch&#x27;s code will be deployed to production, and this is where the deployment process kicks in.</p><p>While most deployment processes utilize version control systems, the path from version control to deployment can vary significantly, and it can be either manual or automatic.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="22-manual-deployments-are-slow-and-unreliable">2.2 Manual Deployments are Slow and Unreliable<a href="#22-manual-deployments-are-slow-and-unreliable" class="hash-link" aria-label="Direct link to 2.2 Manual Deployments are Slow and Unreliable" title="Direct link to 2.2 Manual Deployments are Slow and Unreliable">​</a></h3><p>Manual deployments are time-consuming. Firstly, there is usually a delay between the deployment request and the start of deployment procedures. The code ready for release remains in the version control system until the person or team responsible for deployment is notified.</p><p>Once the deployment process kicks off, teams must perform a long series of tasks to bring that code to production. This might include running scripts, adjusting configuration, checking code quality, and monitoring progress. When multiple teams are responsible for different parts of the deployment process, scheduling and coordination issues could cause delays. For example, TrueCar&#x27;s release cycle involved Change Management tickets, which each team had to file eight days before deployment.</p><p><img loading="lazy" alt="Manual deployment delays" src="/assets/images/manual-deployment-delays-894477d3f161f9e3e7a418f32fdf367d.svg" width="1162" height="359" class="img_ev3q"></p><p>Additionally, manual deployments are error-prone and can lead to unexpected bugs entering production. Humans are bad at performing rote activities, leading to errors when configuring servers, setting up environments, and performing manual tests. To make matters worse, team members often use different operating systems with different environmental configurations. By extension, the team members’ machines might be configured differently from production servers. Even if tests pass locally, they might not pass in production, introducing bugs into the system.</p><p><img loading="lazy" alt="Same app different results" src="/assets/images/same-app-different-results-958bca494ed7fe7e2b922f19b3902c02.svg" width="700" height="330" class="img_ev3q"></p><p>By defining deployment steps as part of a partially or fully automated pipeline, teams can achieve greater consistency and repeatability, resulting in faster and more reliable deployments.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="23-automated-deployments-improve-speed-and-reliability">2.3 Automated Deployments Improve Speed and Reliability<a href="#23-automated-deployments-improve-speed-and-reliability" class="hash-link" aria-label="Direct link to 2.3 Automated Deployments Improve Speed and Reliability" title="Direct link to 2.3 Automated Deployments Improve Speed and Reliability">​</a></h3><p>When a deployment process evolves from manual execution of scripts to an automated series of interconnected steps, it becomes known as a <strong>deployment pipeline</strong>. CI/CD (continuous integration and continuous delivery) is a methodology that embraces such automation. CI/CD pipelines provide superior guarantees that the deployment steps will be executed in a consistent and repeatable way, resulting in faster and more reliable deployments.</p><p>Automated deployments treat version control systems as more than just code storage solutions. Version control systems plug directly into deployment pipelines. Since version control systems are notified when developers make a commit, they can automatically trigger whatever automated system is responsible for deploying the code, which will carry out the deployment process. This eliminates delay between deployment requests and pipeline initiation. This is in stark contrast to manual deployments, where such delays are common.</p><p><img loading="lazy" alt="Manual vs automatic deployment" src="/assets/images/manual-vs-automatic-deployment-e1166efdcdc6bdcfebf66ff36772e065.svg" width="852" height="339" class="img_ev3q"></p><p>Choosing to <em>fully</em> automate deployments all the way through production can drastically shorten the time between release cycles, improving the rate at which QA and customers can provide feedback. For example, once TrueCar switched from a waterfall-style approach to a fully automated pipeline, they transitioned from a “burdensome weekly release cycle to deploying code up to 100 times per week”.</p><p>Automated deployments provide greater reliability by significantly reducing the possibility of human error. An automated pipeline is less prone to mistakes as it executes commands automatically, eliminating the need for human intervention.Quality checks, such as linting and testing, are integrated directly into the pipelines to ensure they are consistently performed with every deployment. Automated testing plays a crucial role in identifying bugs early on, allowing for incremental fixes to be made and preventing issues from accumulating.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="3-cicd-pipelines">3. CI/CD Pipelines<a href="#3-cicd-pipelines" class="hash-link" aria-label="Direct link to 3. CI/CD Pipelines" title="Direct link to 3. CI/CD Pipelines">​</a></h2><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="31-stages-of-a-cicd-pipeline">3.1 Stages of a CI/CD Pipeline<a href="#31-stages-of-a-cicd-pipeline" class="hash-link" aria-label="Direct link to 3.1 Stages of a CI/CD Pipeline" title="Direct link to 3.1 Stages of a CI/CD Pipeline">​</a></h3><p>A deployment pipeline is essential for delivering code changes from development to production. Although there is no one-size-fits-all pipeline, the steps typically fall under one of the following four stages:</p><ol><li>The <strong>Source stage</strong> connects the pipeline to a repository hosting platform such as GitHub. Specified triggers such as opening a pull request or merging into main will initiate the pipeline.</li><li>The <strong>Testing stage</strong> executes tests against the updated application to ensure code quality and verify that the code functions as expected. Standard forms of testing include static code analysis, unit testing, and integration testing. Static code analysis checks for stylistic issues and basic programmatic vulnerabilities; tools include ESLint and RuboCop. Unit testing verifies the functionality of code components individually; tools include Jest and RSpec. Integration testing confirms proper interactions between application components; tools include Cypress and Selenium.</li><li>The <strong>Build stage</strong> bundles the updated source code with its dependencies and compiles this into a single deployable artifact; tools include Webpack and Docker.</li><li>The <strong>Deployment stage</strong> deploys the built artifact to one or more environments. Typically, this includes a Staging (Pre-Production) environment used by QA teams to review the application and give approval, as well as a Production environment that is accessible to end users and represents the final outcome of the deployment process. Examples of deployment destinations are Amazon Web Services (AWS) Fargate and Google Cloud Run.</li></ol><p><img loading="lazy" alt="Stages" src="/assets/images/stages-20e1f509374cdf4c8da9345c75833898.svg" width="1559" height="557" class="img_ev3q"></p><p>Most deployments follow these stages, but the degree to which the pipeline is automated depends on the level of adoption of continuous integration, delivery, and deployment.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="32-continuous-integration-delivery-and-deployment">3.2 Continuous Integration, Delivery, and Deployment<a href="#32-continuous-integration-delivery-and-deployment" class="hash-link" aria-label="Direct link to 3.2 Continuous Integration, Delivery, and Deployment" title="Direct link to 3.2 Continuous Integration, Delivery, and Deployment">​</a></h3><p>CI/CD pipelines aim to fulfill three primary objectives, but it is rare for most pipelines to achieve all three completely. These objectives are continuous integration, continuous delivery, and continuous deployment.</p><p>Continuous integration is the practice of regularly merging code into the main branch of a central repository after passing a series of tests. Continuous delivery extends continuous integration by automatically preparing code changes for release, without necessarily releasing them. Continuous deployment is the hallmark of a well-established CI/CD system: executed builds are immediately released into production.</p><p><img loading="lazy" alt="CI/CD" src="/assets/images/cicd-simplified-0c327a319f6641d1b60ec82f5a89ccd5.svg" width="958" height="593" class="img_ev3q"></p><p>As companies adopt continuous integration, delivery, and deployment practices to different extents, they must consider a new tradeoff: how to balance safety with velocity.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="4-balancing-safety-and-velocity">4. Balancing Safety and Velocity<a href="#4-balancing-safety-and-velocity" class="hash-link" aria-label="Direct link to 4. Balancing Safety and Velocity" title="Direct link to 4. Balancing Safety and Velocity">​</a></h2><p>Introducing automation can result in an inevitable tradeoff. While faster code deployment shortens the development lifecycle, it may also increase the likelihood of bugs and errors. Conversely, prioritizing safety by running more tests and validations can reduce velocity.</p><p>Teams can make a number of CI/CD-related decisions to fine-tune the location of their deployment pipeline on this safety-velocity spectrum.</p><ol><li><strong>Branching Strategy:</strong> Traditional feature branching workflows such as GitHub Flow prioritize safety by reducing the risk of bad code being pushed to main. In contrast, trunk-based development prioritizes speed by encouraging direct commits to main.</li></ol><p><img loading="lazy" alt="Branching strategies" src="/assets/images/branching-strategies-da54dc7b964fab0fbe0bbdc0cceffcde.svg" width="1269" height="835" class="img_ev3q"></p><ol start="2"><li><strong>Merging Strategy:</strong> Teams that adopt a feature branching workflow can automatically merge pull requests if tests pass or require a team member to manually perform the merge. While auto-merging can speed up the pipeline, it may lead to merging code that has not been adequately tested and reviewed if the auto-merge criteria are not carefully selected.</li></ol><p><img loading="lazy" alt="Auto merge" src="/assets/images/auto-merge-bd6beb94cf6047043060205fc130df76.svg" width="1551" height="420" class="img_ev3q"></p><ol start="3"><li><strong>Continuous Deployment:</strong> Once code passes tests and is packaged into a build artifact, the pipeline deploys it straight to production without first using a pre-production environment. This enables teams to deliver the product to end users faster.</li></ol><p>CI/CD tools can be configured to address the challenge of balancing safety and velocity. However, new challenges arise when CI/CD pipelines are used for different application architectures such as monoliths and microservices.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="5-cicd-for-monoliths-and-microservices">5. CI/CD for Monoliths and Microservices<a href="#5-cicd-for-monoliths-and-microservices" class="hash-link" aria-label="Direct link to 5. CI/CD for Monoliths and Microservices" title="Direct link to 5. CI/CD for Monoliths and Microservices">​</a></h2><p>A monolithic application is a single unit containing tightly-coupled components. Its business logic is housed in a single codebase, often a single repository. A microservices architecture consists of independent, loosely coupled services distributed across the network; it may use multiple repositories. Monolithic architecture has historically been the dominant approach to building applications, but this has shifted toward microservices out of a need for more agility and scalability. The differences in these architectures means that they use CI/CD pipelines in different ways, each accompanied by a distinct set of challenges.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="51-different-communication-methods">5.1 Different Communication Methods<a href="#51-different-communication-methods" class="hash-link" aria-label="Direct link to 5.1 Different Communication Methods" title="Direct link to 5.1 Different Communication Methods">​</a></h3><p>The way an application’s components communicate determines how tests are performed, which influences how a CI/CD pipeline’s Test stage is configured. All components of a monolith run within the same application, usually in a singular process. The application’s modules communicate via function calls, which are fast and reliable. In contrast, microservices communicate remotely via network calls (e.g. using HTTP), which can be slow and unreliable due to network issues. This means that CI/CD pipelines for microservices must offer more complex functionality to perform inter-service testing over the network.</p><p><img loading="lazy" alt="Monolith vs microservices" src="/assets/images/monolith-microservices-b11e7d5118f329a5f5f797ef242ebb02.svg" width="1211" height="395" class="img_ev3q"></p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="52-different-deployment-methods">5.2 Different Deployment Methods<a href="#52-different-deployment-methods" class="hash-link" aria-label="Direct link to 5.2 Different Deployment Methods" title="Direct link to 5.2 Different Deployment Methods">​</a></h3><p>For monoliths the entire codebase is compiled into a single executable that is deployed to production. In contrast, microservices are deployed as independent units. This is an advantage because small services are easier to update compared to a large monolith. Microservices are smaller and have fewer dependencies than a monolith, which speeds up deployment and reduces time-to-market. Furthermore, microservices are fully decoupled so each service can be deployed on its own schedule without impacting the others.</p><p><img loading="lazy" alt="Releasing microservices" src="/assets/images/releasing-microservices-8ebf562d256cd7d434183d96708e0eb9.svg" width="957" height="406" class="img_ev3q"></p><p>The ability to independently deploy and release microservices is a chief benefit of microservice architectures. However, it introduces the problem of needing to manage multiple pipelines.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="6-cicd-challenges-with-microservices">6. CI/CD Challenges with Microservices<a href="#6-cicd-challenges-with-microservices" class="hash-link" aria-label="Direct link to 6. CI/CD Challenges with Microservices" title="Direct link to 6. CI/CD Challenges with Microservices">​</a></h2><p>Implementing a CI/CD pipeline can differ quite a bit for monoliths and microservices. Let’s explore these differences and the specific challenges faced by microservice-oriented CI/CD pipelines.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="61-pipeline-management-challenges">6.1 Pipeline Management Challenges<a href="#61-pipeline-management-challenges" class="hash-link" aria-label="Direct link to 6.1 Pipeline Management Challenges" title="Direct link to 6.1 Pipeline Management Challenges">​</a></h3><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="the-many-pipeline-problem">The Many-Pipeline Problem<a href="#the-many-pipeline-problem" class="hash-link" aria-label="Direct link to The Many-Pipeline Problem" title="Direct link to The Many-Pipeline Problem">​</a></h4><p>One approach to fully decoupling microservice deployments is to attach an individual CI/CD pipeline to each service. Since microservice teams are usually autonomous, it is common for teams to build their own pipelines. A benefit of this approach is that teams have full control and can customize all pipeline steps.</p><p>However, this many-pipeline approach adds complexity. Internal teams must now maintain numerous pipelines and their associated YAML files, scripts, and software versions. For example, when Expedia experienced an “explosion in the number of CI/CD pipelines”, the engineering teams found that they were “constantly needing to update” the pipelines for each microservice.</p><p><img loading="lazy" alt="Many pipelines" src="/assets/images/many-pipelines-697cfd4597b842b30c367c5cc639140a.svg" width="747" height="442" class="img_ev3q"></p><p>The problem becomes worse as microservice architectures scale. With so many pipelines in the system, teams often have a hard time keeping up with how to build, test, and deploy each microservice. This could make it challenging for them to make system-wide adjustments quickly, for example rolling back a buggy microservice that has broken the production system.</p><p>In order to ease the burden of managing CI/CD for tens or potentially hundreds of microservices, modularization techniques have emerged in the CI/CD space.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="the-shared-segment-solution">The Shared Segment Solution<a href="#the-shared-segment-solution" class="hash-link" aria-label="Direct link to The Shared Segment Solution" title="Direct link to The Shared Segment Solution">​</a></h4><p>One solution for modularizing CI/CD pipelines across microservices is to reuse the same sequence of steps, known as segments, for different microservice pipelines. These shared segments could come in the form of shell scripts, reusable Docker images, repositories or libraries, or YAML templates containing deployment-related logic.</p><p>However, there are some major downsides to this approach. For one, it still requires bootstrapping and maintaining an individual pipeline for each microservice. Secondly, the shared pipeline segments themselves need to be maintained.</p><p><img loading="lazy" alt="Shared segments" src="/assets/images/shared-segments-2cc3c9d0eb04584e8a743cdcce18667e.svg" width="560" height="606" class="img_ev3q"></p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="the-single-parameterized-pipeline-solution">The Single, Parameterized Pipeline Solution<a href="#the-single-parameterized-pipeline-solution" class="hash-link" aria-label="Direct link to The Single, Parameterized Pipeline Solution" title="Direct link to The Single, Parameterized Pipeline Solution">​</a></h4><p>In the many-pipeline approach, each microservice has its own dedicated CI/CD pipeline. However, these pipelines can be made more flexible and reusable by parameterizing them. For instance, instead of linking a pipeline to a single repository URL, testing command, and entry points to configuration files, these values can be configurable for each service. This means that adding an additional microservice to the pipeline is simply a matter of configuring these parameters.</p><p><img loading="lazy" alt="Shared pipeline" src="/assets/images/shared-pipeline-2dc4889e8821c967d3e5fb363ff2675e.svg" width="807" height="356" class="img_ev3q"></p><p>While this single-pipeline approach can offer significant benefits in terms of efficiency and consistency, it may not be the best fit for every team. To make it work, there must be a certain degree of uniformity across microservices in terms of how they are compiled, packaged, tested, and deployed. For microservices with more heterogeneous deployment requirements, a different approach may be needed.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="62-microservice-testing-challenges">6.2 Microservice Testing Challenges<a href="#62-microservice-testing-challenges" class="hash-link" aria-label="Direct link to 6.2 Microservice Testing Challenges" title="Direct link to 6.2 Microservice Testing Challenges">​</a></h3><p>As a reminder, a monolithic application runs in its own process, meaning components need not communicate over the network to interact. Running tests that verify components or modules in an application interface properly together is merely a matter of making function calls within that process.</p><p>On the contrary, microservices each run in their own process and are distributed across the network. It follows that testing microservice interactions also requires making network calls.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="solutions-for-testing-service-interactions">Solutions for Testing Service Interactions<a href="#solutions-for-testing-service-interactions" class="hash-link" aria-label="Direct link to Solutions for Testing Service Interactions" title="Direct link to Solutions for Testing Service Interactions">​</a></h4><p>There are countless possible setups for testing the interactions between microservices, but some of the most common are:</p><ul><li>Test the service against a service spun up only for testing.</li><li>Test the service against a production instance of another service.</li><li>Run an entire pre-production environment to test the system as a whole.</li></ul><p><img loading="lazy" alt="Microservice testing" src="/assets/images/microservice-testing-0fb3a057e65e9af7d5dd20ef129cf177.svg" width="933" height="560" class="img_ev3q"></p><p>There are advantages and disadvantages to each of these techniques, so a comprehensive CI/CD pipeline testing strategy will usually employ a combination of them.</p><p>Now that we’ve looked into what a CI/CD pipeline for microservices looks like, let’s walk through steps a development team might need to take to implement a CI/CD pipeline for microservices on their own.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="7-manually-building-a-cicd-pipeline-for-microservices">7. Manually Building a CI/CD Pipeline for Microservices<a href="#7-manually-building-a-cicd-pipeline-for-microservices" class="hash-link" aria-label="Direct link to 7. Manually Building a CI/CD Pipeline for Microservices" title="Direct link to 7. Manually Building a CI/CD Pipeline for Microservices">​</a></h2><p>Building a CI/CD pipeline from scratch can be a time-consuming and difficult endeavor, especially if we are designing it to handle the inherent complexities of a microservices architecture. Smaller teams with limited experience with cloud infrastructure and automation may struggle to architect a robust pipeline. They might also lack the staff and expertise to maintain and optimize it. The following is an example list of tasks for setting up a pipeline on AWS.</p><p><img loading="lazy" alt="Building a pipeline" src="/assets/images/building-a-pipeline-c6c5d098d19ae5716ddcfe8b8bb66b53.svg" width="1073" height="803" class="img_ev3q"></p><p>Instead of investing significant time and effort into this DIY project, teams may choose to leverage existing CI/CD solutions to simplify the process.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="8-existing-solutions">8. Existing Solutions<a href="#8-existing-solutions" class="hash-link" aria-label="Direct link to 8. Existing Solutions" title="Direct link to 8. Existing Solutions">​</a></h2><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="81-diy-solutions">8.1 DIY Solutions<a href="#81-diy-solutions" class="hash-link" aria-label="Direct link to 8.1 DIY Solutions" title="Direct link to 8.1 DIY Solutions">​</a></h3><p>There are many free open-source DIY CI/CD tools such as Jenkins and Tekton. These tools offer a high level of customization and configurability, which allows the tool to be tailored for close alignment to a specific use case.</p><p>Jenkins achieves this level of customization through integration with numerous available plugins. This allows users to add functionality to Jenkins and tailor it to their needs. These tools also allow for pipeline modularization and reusability. For example, Jenkins accomplishes pipeline modularization through shared libraries while Tekton allows for the reusability of different subcomponents, such as tasks and pipelines.</p><p>However, these tools also come with the disadvantage of having a steep learning curve due to their high configurability, which makes the setup procedure more complex. For Jenkins, users need to have knowledge of relevant plugins that are needed to achieve the desired functionality. For Tekton, experience with Kubernetes is required since it runs as an extension on a Kubernetes cluster.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="82-commercial-solutions">8.2 Commercial Solutions<a href="#82-commercial-solutions" class="hash-link" aria-label="Direct link to 8.2 Commercial Solutions" title="Direct link to 8.2 Commercial Solutions">​</a></h3><p>There are various commercial CI/CD pipelines available such as Codefresh, Semaphore, CircleCI, and AWS CodePipeline. Like the open-source tools, these solutions usually provide a high degree of customizability. For example, a YAML file might be used to configure the pipeline and fully customize the stages and their sequence.</p><p>Many commercial CI/CD solutions offer pipeline modularization and reusability. With CodeFresh, a single pipeline can be linked to multiple repositories, and the associated environment variables can be passed to the pipeline stages for use. Semaphore supports a monorepo approach, in which multiple applications, stored in the same repository, can each be linked to a variation of the same CI/CD pipeline.</p><p>Some commercial CI/CD solutions make testing microservice interactions easier. For example, Codefresh allows the user to specify “sidecar containers” as part of pipelines, using Docker Compose under the hood to provision an environment to run integration tests.</p><p>However, commercial solutions may not be suitable for all scenarios. They are not as extensible as open-source solutions and may lack sensible default settings, despite being generally easier to use.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="83-a-solution-for-our-use-case">8.3 A Solution for Our Use Case<a href="#83-a-solution-for-our-use-case" class="hash-link" aria-label="Direct link to 8.3 A Solution for Our Use Case" title="Direct link to 8.3 A Solution for Our Use Case">​</a></h3><p>We wanted to build a solution for a specific use case. The solution would be open source as well as fully self-hosted on a user’s AWS infrastructure allowing for complete control of code and data ownership. Next, the solution should be easy for users to set up and immediately integrate into their existing infrastructure. Here, the goal is to have low-configuration as well as sensible default settings that can meet the typical demands placed on a CI/CD pipeline. The solution should make managing deployment of multiple microservices easy through the use of a single, reusable, pipeline for every service. Lastly, the solution should provide options for testing microservice interactions.</p><p><img loading="lazy" alt="Comparison chart" src="/assets/images/comparison-chart-0e51cb8eb59d227702fa47c04e6fe331.svg" width="868" height="392" class="img_ev3q"></p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="9-introducing-seamless">9. Introducing Seamless<a href="#9-introducing-seamless" class="hash-link" aria-label="Direct link to 9. Introducing Seamless" title="Direct link to 9. Introducing Seamless">​</a></h2><p>Seamless is an open-source CI/CD pipeline tool designed specifically for containerized microservices deployed to AWS Elastic Container Service (ECS) Fargate. It offers a user-friendly interface that is similar to many of the popular interfaces found in commercial solutions. Unlike other CI/CD pipelines, Seamless does not require user-defined scripting through a YAML file template for configuration. Instead, Seamless relies on a core set of default stages: Prepare, Code Quality, Unit Test, Build, Integration Test, Deploy to Staging, and Deploy to Production. This approach makes Seamless easy to use right out of the box. Through the interface, users can simply provide the necessary commands needed to execute each stage, allowing for a more intuitive configuration.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="91-setting-up-seamless">9.1 Setting Up Seamless<a href="#91-setting-up-seamless" class="hash-link" aria-label="Direct link to 9.1 Setting Up Seamless" title="Direct link to 9.1 Setting Up Seamless">​</a></h3><p>Using Seamless requires:</p><ul><li>An AWS account</li><li>npm installed</li><li>The AWS CLI installed and configured (Seamless will use the locally configured AWS account)</li><li>The AWS CDK command line tool installed</li></ul><p>To install Seamless, run <code>npm install -g seamless</code>. Running <code>seamless init</code> will guide the user through a series of inputs needed to deploy Seamless. After completing the initialization process, executing <code>seamless deploy</code> will provision Seamless&#x27;s infrastructure on AWS and provide a URL to access the platform&#x27;s dashboard. The user can then navigate to the dashboard and start using Seamless.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="92-using-seamless">9.2 Using Seamless<a href="#92-using-seamless" class="hash-link" aria-label="Direct link to 9.2 Using Seamless" title="Direct link to 9.2 Using Seamless">​</a></h3><p>The dashboard provides users with the ability to set up their pipeline and manage the associated services. When setting up the pipeline, the user will provide their ECS Cluster information for both production and staging environments. This allows for streamlined management of the pipeline and its services, providing users with a centralized location to manage all aspects of their deployment process.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="connecting-services-to-the-pipeline">Connecting Services to the Pipeline<a href="#connecting-services-to-the-pipeline" class="hash-link" aria-label="Direct link to Connecting Services to the Pipeline" title="Direct link to Connecting Services to the Pipeline">​</a></h3><p>The dashboard provides users with the ability to set up their pipeline and manage the associated services. When setting up the pipeline, the user will provide their ECS Cluster information for both production and staging environments.</p><p>After setting up the pipeline, the user can proceed to create services that will utilize the pipeline. The service setup process collects all the necessary information to run the pipeline, verify code functionality, and promote it to production. This accessible interface replaces a YAML file (or equivalent configuration) in many current solutions.</p><p><strong>(GIF of service setup form)</strong></p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="running-the-pipeline">Running the Pipeline<a href="#running-the-pipeline" class="hash-link" aria-label="Direct link to Running the Pipeline" title="Direct link to Running the Pipeline">​</a></h3><p>To activate the pipeline, the user can select from several triggers, including Push on Main, Open Pull Request, and Synchronize Pull Request. When Push on Main is triggered, it executes the full pipeline, while the Pull Request Options trigger a partial pipeline execution. Additionally, there is an option to manually execute the through a rerun feature included on the services page. Each service can be individually rerun with a button click.</p><p><img loading="lazy" alt="Pipeline triggers" src="/assets/images/pipeline-triggers-209d7fc1ced3c3addbb55fbe0e705aff.svg" width="1367" height="664" class="img_ev3q"></p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="monitoring-the-pipeline">Monitoring the Pipeline<a href="#monitoring-the-pipeline" class="hash-link" aria-label="Direct link to Monitoring the Pipeline" title="Direct link to Monitoring the Pipeline">​</a></h3><p>Seamless provides real-time monitoring of pipeline execution. The UI displays live updates of both runs and stages, enabling users to stay informed of pipeline outcomes as runs and stages transition from “Idle” to “In Progress”, and ultimately to “Success” or “Failure”. Log data for each stage is updated live, making it easier to identify and troubleshoot errors when they occur.</p><p><strong>(GIF of live status updates)</strong></p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="10-seamlesss-architecture">10. Seamless’s Architecture<a href="#10-seamlesss-architecture" class="hash-link" aria-label="Direct link to 10. Seamless’s Architecture" title="Direct link to 10. Seamless’s Architecture">​</a></h2><p>To take advantage of the scalability and flexibility of cloud computing, we built Seamless’s infrastructure on AWS using the Cloud Development Kit (CDK).</p><p>When source code is updated, GitHub sends a webhook to start the pipeline. An Express.js backend running in an ECS Fargate cluster receives requests through an HTTP API Gateway. For each run, it retrieves pipeline data information from the PostgreSQL database (Relational Database Service — RDS) and sends it to the state machine (Step Function). The state machine executes each pipeline task in a container in ECS (EC2 launch type). All task containers mount a shared Docker volume on an Elastic File System (EFS) and can access the Elastic Container Registry for pushing or pulling required images. The updated source code is deployed to staging and production Fargate clusters.</p><p>During the pipeline run, the state machine sends status updates to the backend for storage in the database, and to users via the notification service. The task containers send logs to the backend to be inserted into the log cache (ElastiCache Redis). The backend sends both status updates and logs to the frontend dashboard via a WebSockets connection maintained by an API Gateway.</p><p><img loading="lazy" alt="Architecture" src="/assets/images/architecture-simplified-606d977b67bdd8ce20e460ad2a7feb66.svg" width="1358" height="903" class="img_ev3q"></p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="11-building-the-core-pipeline-functionality">11. Building the Core Pipeline Functionality<a href="#11-building-the-core-pipeline-functionality" class="hash-link" aria-label="Direct link to 11. Building the Core Pipeline Functionality" title="Direct link to 11. Building the Core Pipeline Functionality">​</a></h2><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="111-modeling-and-storing-data">11.1 Modeling and Storing Data<a href="#111-modeling-and-storing-data" class="hash-link" aria-label="Direct link to 11.1 Modeling and Storing Data" title="Direct link to 11.1 Modeling and Storing Data">​</a></h3><p>Our data model comprises four fundamental entities: Pipelines, Services, Runs, and Stages. To embrace our single-pipeline, many services approach, we aimed to ensure our data model reflected this by creating a one-to-many relationship between Pipelines and Services. Additionally, each Service can have many Runs, and each Run can have many Stages.</p><p>Given our schema&#x27;s fixed nature, we chose to store our data in PostgreSQL, a relational database. We rely on the Prisma ORM to simplify schema creation and migration, as well as data manipulation.</p><p><img loading="lazy" alt="ERD" src="/assets/images/one-to-many-79c87028e654b1d92846102c79c5a3b6.svg" width="1674" height="467" class="img_ev3q"></p><p>To accommodate the potentially high write speeds required to store logs generated by task containers, we sought a storage mechanism capable of supporting this. As a result, we decided to use a Redis cache (specifically, AWS ElastiCache) to meet our needs.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="112-managing-pipeline-execution">11.2 Managing Pipeline Execution<a href="#112-managing-pipeline-execution" class="hash-link" aria-label="Direct link to 11.2 Managing Pipeline Execution" title="Direct link to 11.2 Managing Pipeline Execution">​</a></h3><p>Pipelines execute tasks across multiple services, and we wanted a central orchestrator to manage the execution flow. We handled this using a state machine, which is a model for representing system behavior. It enabled us to define all potential states and the events that would trigger a transition from one state to another. One drawback is that defining states in advance can limit the ability to add new steps dynamically. As a result, the logic of the pipeline would remain unchanged from the beginning. We determined that this tradeoff was acceptable for our use case.</p><p><img loading="lazy" alt="State machine example" src="/assets/images/state-machine-example-b9beada3e80c508fe2d0383179c4b6af.svg" width="998" height="390" class="img_ev3q"></p><p>We chose AWS Step Functions (state machine service) for its integration with other AWS services, flow visualizations, and built-in functionality for error handling. Before and after each state, we added steps to report system status to our backend. We also evaluated the XState JavaScript library, but it lacked native AWS integrations and proved more complex to scale and persist state.</p><p>We considered job queues as an alternative to state machines, but decided against it due to the difficulty in passing data between jobs and ensuring only one stage executed at a time. Another alternative was an event-driven architecture where each task would call the next, and there would be no orchestrator. However, we felt that having a central place to manage state made it easier to understand and debug.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="113-running-tasks">11.3 Running Tasks<a href="#113-running-tasks" class="hash-link" aria-label="Direct link to 11.3 Running Tasks" title="Direct link to 11.3 Running Tasks">​</a></h3><p>For the actual tasks themselves, we use containers on ECS/EC2, Amazon’s Elastic Container Service. Containers provide consistent environments, so multiple pipeline runs will behave the same way. They are lightweight, containing only necessary dependencies, and are ephemeral and elastic, meaning that ECS spins them up and down automatically to match demand. This aligns with our use case as pipeline tasks are ephemeral, and their demand varies depending on the timing of the pipeline runs. However, there are some downsides including cold start delays, management of the underlying EC2 instances, and needing to configure a shared persistent data store.</p><p><img loading="lazy" alt="Task containers" src="/assets/images/task-containers-74dd7176926b8794b8de9f10aace7032.svg" width="801" height="655" class="img_ev3q"></p><p>We looked into alternative approaches, such as running containers on ECS Fargate, which would reduce management overhead, but it was unsuitable due to our need for Docker-in-Docker functionality. This is required for tasks such as building services as images, where Docker needs to run within our task runners. Another option was to run task logic directly on virtual machines, which would be easier to implement but would increase the management overhead and be less resource-efficient than using containers. It would also require configuring Amazon Machine Images and configuration management tools. Ultimately, we determined that using containers on ECS/EC2 was the most effective solution for our needs.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="114-automating-pipeline-runs">11.4 Automating Pipeline Runs<a href="#114-automating-pipeline-runs" class="hash-link" aria-label="Direct link to 11.4 Automating Pipeline Runs" title="Direct link to 11.4 Automating Pipeline Runs">​</a></h3><p>The pipeline runs automatically in response to changes in source code, and no manual intervention is required. During setup, the user chooses what triggers a run: Push to Main, Pull Request Open, and/or Pull Request Synchronize. Seamless creates a webhook in the repository. The backend uses the webhook payload to identify the trigger and initiate the appropriate pipeline process (partial or full run).</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="12-improving-core-functionality">12. Improving Core Functionality<a href="#12-improving-core-functionality" class="hash-link" aria-label="Direct link to 12. Improving Core Functionality" title="Direct link to 12. Improving Core Functionality">​</a></h2><p>Once Seamless’s core functionality was working, we added features and optimizations to improve pipeline performance and user experience.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="121-sharing-data-among-containers">12.1 Sharing Data Among Containers<a href="#121-sharing-data-among-containers" class="hash-link" aria-label="Direct link to 12.1 Sharing Data Among Containers" title="Direct link to 12.1 Sharing Data Among Containers">​</a></h3><p>To minimize repeated work, we needed to ensure that multiple pipeline tasks could access the same files. For example, the Prepare Stage clones the source code so the Build Stage can package it into a Docker image later. To achieve this, we used the AWS EFS network file system, which is designed to be mounted to any number of EC2 instances or ECS containers. EFS is elastic and provides the necessary storage without needing to specify capacity in advance.</p><p>When each container is started, it is automatically mounted to a shared persistent Docker volume on EFS. The git commit hash serves as the directory name for the source code, which prevents naming conflicts and enables parallel pipeline execution. We also considered block storage, which had higher performance, but it was not suitable because it was not designed to connect to multiple containers.</p><p><img loading="lazy" alt="NFS" src="/assets/images/nfs-6bee67c83988e313985365803aec6f72.svg" width="530" height="372" class="img_ev3q"></p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="122-running-docker-commands-inside-docker-containers">12.2 Running Docker Commands Inside Docker Containers<a href="#122-running-docker-commands-inside-docker-containers" class="hash-link" aria-label="Direct link to 12.2 Running Docker Commands Inside Docker Containers" title="Direct link to 12.2 Running Docker Commands Inside Docker Containers">​</a></h3><p>Some Task Containers run Docker commands inside. The Build Stage runs <code>docker build</code>, and the Integration Test Stage runs <code>docker compose up</code>. To enable this, we considered the &quot;Docker-in-Docker&quot; (DinD) approach, where a Docker container runs another Docker daemon inside it. However, we chose not to use DinD due to security, storage, and build cache issues. Instead, we opted to bind-mount the container&#x27;s Docker socket with the host machine&#x27;s Docker socket, which grants access to the host&#x27;s Docker daemon. Although this doesn&#x27;t create a nested “parent-child” Docker environment, it allows us to run &quot;sibling&quot; containers at the top level and share the host&#x27;s build cache when starting a container. Since we were only running temporary jobs that didn&#x27;t require a nested environment, this approach was sufficient for our needs.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="123-integration-testing">12.3 Integration Testing<a href="#123-integration-testing" class="hash-link" aria-label="Direct link to 12.3 Integration Testing" title="Direct link to 12.3 Integration Testing">​</a></h3><p>Integration testing involves spinning up multiple containerized services to evaluate inter-service communication and functionality. To facilitate container management and networking, we used Docker Compose. This minimizes potential network faults and latency issues when testing service interactions. It also parallels the user&#x27;s existing workflow if they are already using Docker Compose for local testing. We chose not to use a dedicated Fargate Cluster because it would have been slower and required additional infrastructure.</p><p><img loading="lazy" alt="Integration test" src="/assets/images/integration-test-c6006f8344e1172555bfdb897a60a4de.svg" width="871" height="693" class="img_ev3q"></p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="124-manual-approval-of-staging-environments">12.4 Manual Approval of Staging Environments<a href="#124-manual-approval-of-staging-environments" class="hash-link" aria-label="Direct link to 12.4 Manual Approval of Staging Environments" title="Direct link to 12.4 Manual Approval of Staging Environments">​</a></h3><p>When integrating the state machine with other services, we had two primary patterns to choose from: Synchronous Jobs and Wait for a Callback Token. The synchronous model was suitable for most stages because each stage should automatically start after the previous one finishes. However, if the user disables Auto-Deploy, the state machine should pause so the developer can perform quality checks on the staging environment. This second scenario was a good use case for the Wait for a Callback Token pattern.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="125-rollbacks">12.5 Rollbacks<a href="#125-rollbacks" class="hash-link" aria-label="Direct link to 12.5 Rollbacks" title="Direct link to 12.5 Rollbacks">​</a></h3><p>Rollbacks are a critical feature because they allow teams to revert to a previous stable version in case of unexpected issues. To enable rollbacks, we tag all Docker images with the git commit hash. Our UI displays all possible rollback images, giving users a choice of rollback targets. Each service can be rolled back independently, minimizing the impact on the overall deployment.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="126-automatic-deployment-of-fargate-clusters">12.6 Automatic Deployment of Fargate Clusters<a href="#126-automatic-deployment-of-fargate-clusters" class="hash-link" aria-label="Direct link to 12.6 Automatic Deployment of Fargate Clusters" title="Direct link to 12.6 Automatic Deployment of Fargate Clusters">​</a></h3><p>To streamline the deployment process, we built a CDK feature that automatically deploys their Docker images to a Fargate Cluster and implements service discovery using AWS Service Connect. This approach helps users become productive quickly, as they only need to provide basic information about their service and its image. The feature can be used to set up both staging and production environments.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="13-beyond-the-core-pipeline">13. Beyond the Core Pipeline<a href="#13-beyond-the-core-pipeline" class="hash-link" aria-label="Direct link to 13. Beyond the Core Pipeline" title="Direct link to 13. Beyond the Core Pipeline">​</a></h2><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="131-designing-for-performance-and-scale">13.1 Designing for Performance and Scale<a href="#131-designing-for-performance-and-scale" class="hash-link" aria-label="Direct link to 13.1 Designing for Performance and Scale" title="Direct link to 13.1 Designing for Performance and Scale">​</a></h3><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="serverless-backend">Serverless Backend<a href="#serverless-backend" class="hash-link" aria-label="Direct link to Serverless Backend" title="Direct link to Serverless Backend">​</a></h4><p>Seamless’s backend is a containerized Express.js application running on Fargate, which will spin up as many containers as needed in response to demand. This ensures that it can handle a large number of incoming requests without sacrificing performance.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="parallel-execution-of-state-machines">Parallel Execution of State Machines<a href="#parallel-execution-of-state-machines" class="hash-link" aria-label="Direct link to Parallel Execution of State Machines" title="Direct link to Parallel Execution of State Machines">​</a></h4><p>Seamless enables parallel execution of state machines by utilizing separate instances of AWS Step Functions. This allows for concurrent execution, enabling different microservices to use the shared pipeline simultaneously. As a result, queuing pipeline executions becomes unnecessary and multiple microservices can be deployed at the same time.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="132-notifications">13.2 Notifications<a href="#132-notifications" class="hash-link" aria-label="Direct link to 13.2 Notifications" title="Direct link to 13.2 Notifications">​</a></h3><p>Seamless offers integration with AWS Simple Notification Service (SNS), allowing for notifications to be sent via email, Slack, and PagerDuty. This feature provides added convenience and flexibility for users, ensuring that they can stay up-to-date with pipeline execution and quickly address any issues that arise.</p><p><img loading="lazy" alt="Notifications" src="/assets/images/status-updates-notifications-0b423418844aaa373dc44734f77c820d.svg" width="842" height="646" class="img_ev3q"></p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="133-logging">13.3 Logging<a href="#133-logging" class="hash-link" aria-label="Direct link to 13.3 Logging" title="Direct link to 13.3 Logging">​</a></h3><p>We developed a system to capture logs from all task containers, storing them in Redis with a 48-hour expiration time. It allows customization of the log payload and labels them using a ULID. We used sorted sets to insert logs in sorted order, eliminating the need for sorting when reading logs. The Dashboard shows users all logs for each stage, and any new logs are sent over WebSockets.</p><p><img loading="lazy" alt="Logging" src="/assets/images/logs-c9bfd52ab488bae845f48b55ac801900.svg" width="866" height="373" class="img_ev3q"></p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="134-basic-security">13.4 Basic Security<a href="#134-basic-security" class="hash-link" aria-label="Direct link to 13.4 Basic Security" title="Direct link to 13.4 Basic Security">​</a></h3><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="oauth">OAuth<a href="#oauth" class="hash-link" aria-label="Direct link to OAuth" title="Direct link to OAuth">​</a></h4><p>Seamless utilizes the OAuth flow, using Github’s OAuth implementation to authenticate users and provide authorization to Github. When a user logs in, they are directed to Github, at which point a temporary code is generated for the user. The user then passes that code to an authorization proxy on Seamless’s backend on subsequent requests. This token is used for a few purposes: to verify that the user is authenticated when they try to access any route on Seamless’s backend, to configure webhooks on the user’s behalf, and to clone the users’ repositories.</p><p><img loading="lazy" alt="OAuth flow" src="/assets/images/oauth-flow-c87fd2b83801538f2ff04372898a0bb0.svg" width="1559" height="677" class="img_ev3q"></p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="private-subnets">Private Subnets<a href="#private-subnets" class="hash-link" aria-label="Direct link to Private Subnets" title="Direct link to Private Subnets">​</a></h4><p>Aside from our public-facing API gateway, most AWS resources in Seamless’s infrastructure are provisioned in private subnets so they can’t accept incoming network traffic. In case a developer needs to interact with resources in private subnets, such as their relational database or Redis cache, we deploy a bastion host that a developer can SSH into.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="14-future-work">14. Future Work<a href="#14-future-work" class="hash-link" aria-label="Direct link to 14. Future Work" title="Direct link to 14. Future Work">​</a></h2><p>Seamless could be improved to support more use cases and offer more functionality. These features include:
Expand deployment options beyond ECS Fargate
Support microservices not built using a Node.js runtime environment.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="references">References<a href="#references" class="hash-link" aria-label="Direct link to References" title="Direct link to References">​</a></h2><p><sup id="fnref-1"><a href="#fn-1" class="footnote-ref">1</a></sup> <a href="https://www.cmswire.com/information-management/version-control-systems-the-link-between-development-and-deployment/" target="_blank" rel="noopener noreferrer">https://www.cmswire.com/information-management/version-control-systems-the-link-between-development-and-deployment/</a></p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#1-introduction" class="table-of-contents__link toc-highlight">1. Introduction</a></li><li><a href="#2-evolution-of-deployment-processes" class="table-of-contents__link toc-highlight">2. Evolution of Deployment Processes</a></li><li><a href="#3-cicd-pipelines" class="table-of-contents__link toc-highlight">3. CI/CD Pipelines</a></li><li><a href="#4-balancing-safety-and-velocity" class="table-of-contents__link toc-highlight">4. Balancing Safety and Velocity</a></li><li><a href="#5-cicd-for-monoliths-and-microservices" class="table-of-contents__link toc-highlight">5. CI/CD for Monoliths and Microservices</a></li><li><a href="#6-cicd-challenges-with-microservices" class="table-of-contents__link toc-highlight">6. CI/CD Challenges with Microservices</a></li><li><a href="#7-manually-building-a-cicd-pipeline-for-microservices" class="table-of-contents__link toc-highlight">7. Manually Building a CI/CD Pipeline for Microservices</a></li><li><a href="#8-existing-solutions" class="table-of-contents__link toc-highlight">8. Existing Solutions</a></li><li><a href="#9-introducing-seamless" class="table-of-contents__link toc-highlight">9. Introducing Seamless</a></li><li><a href="#10-seamlesss-architecture" class="table-of-contents__link toc-highlight">10. Seamless’s Architecture</a></li><li><a href="#11-building-the-core-pipeline-functionality" class="table-of-contents__link toc-highlight">11. Building the Core Pipeline Functionality</a></li><li><a href="#12-improving-core-functionality" class="table-of-contents__link toc-highlight">12. Improving Core Functionality</a></li><li><a href="#13-beyond-the-core-pipeline" class="table-of-contents__link toc-highlight">13. Beyond the Core Pipeline</a></li><li><a href="#14-future-work" class="table-of-contents__link toc-highlight">14. Future Work</a></li><li><a href="#references" class="table-of-contents__link toc-highlight">References</a></li></ul></div></div></div></div></main></div></div></div>
<script src="/assets/js/runtime~main.90f7624f.js"></script>
<script src="/assets/js/main.350b6334.js"></script>
</body>
</html>