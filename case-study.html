<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-case-study">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.0">
<title data-rh="true">Case Study | Seamless</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://seamless-cicd.github.io/case-study"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Case Study | Seamless"><meta data-rh="true" name="description" content="1. Introduction"><meta data-rh="true" property="og:description" content="1. Introduction"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://seamless-cicd.github.io/case-study"><link data-rh="true" rel="alternate" href="https://seamless-cicd.github.io/case-study" hreflang="en"><link data-rh="true" rel="alternate" href="https://seamless-cicd.github.io/case-study" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.9d11a965.css">
<link rel="preload" href="/assets/js/runtime~main.232210d9.js" as="script">
<link rel="preload" href="/assets/js/main.ae001262.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(e){}return e}()||function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,e("light"))}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/seamless-logo-text-dark.svg" alt="Seamless CI/CD" class="themedImage_ToTc themedImage--light_HNdA" width="130"><img src="/img/seamless-logo-text-white.svg" alt="Seamless CI/CD" class="themedImage_ToTc themedImage--dark_i4oU" width="130"></div></a></div><div class="navbar__items navbar__items--right"><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/case-study">Case Study</a><a class="navbar__item navbar__link" href="/presentation">Presentation</a><a class="navbar__item navbar__link" href="/the-team">The Team</a><a class="navbar__item navbar__link" href="/api/pipelines">API</a><a href="https://github.com/seamless-cicd" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><main class="docMainContainer_gTbr docMainContainerEnhanced_Uz_u"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Case Study</h1><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="1-introduction">1. Introduction<a href="#1-introduction" class="hash-link" aria-label="Direct link to 1. Introduction" title="Direct link to 1. Introduction">​</a></h2><p>Seamless is an open-source, low-configuration CI/CD (Continuous Integration and Continuous Delivery/Deployment) framework that streamlines the development and deployment of containerized microservice applications. It automates the building, testing, and deployment of code, enabling developers to deliver software quickly and reliably. Seamless links multiple microservices to a single shared pipeline, eliminating the need to maintain a separate pipeline per service. Throughout this case study, we’ll explore how the deployment process has evolved over time, the role of CI/CD, and how we designed Seamless to support our desired use case.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="2-evolution-of-deployment-processes">2. Evolution of Deployment Processes<a href="#2-evolution-of-deployment-processes" class="hash-link" aria-label="Direct link to 2. Evolution of Deployment Processes" title="Direct link to 2. Evolution of Deployment Processes">​</a></h2><p>A <strong>deployment process</strong> refers to the steps required to make an application accessible to end users. Companies typically care about their deployment process because it impacts:</p><ol><li>The speed at which software can be delivered to end users.</li><li>The confidence the company can have that high-quality, functional code is released.</li></ol><p>The deployment process is initiated with a change in the source code and advances through building, testing, and deploying the code. Most modern companies manage source code through a version control system or VCS.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="version-control-systems">Version Control Systems<a href="#version-control-systems" class="hash-link" aria-label="Direct link to Version Control Systems" title="Direct link to Version Control Systems">​</a></h3><p><strong>Version control systems (VCS)</strong> such as Git enable developers to collaborate on a single, centralized repository.<sup id="fnref-1"><a href="#fn-1" class="footnote-ref">1</a></sup> By creating branches, developers can work on changes independently. After a change is complete, it is typically merged into a central branch called main or master. This is where the deployment process begins.</p><p>While most deployment processes utilize a version control system, the path from version control to deployment can be either <strong>manual</strong> or <strong>automatic</strong>.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="traditional-manual-deployment-processes">Traditional Manual Deployment Processes<a href="#traditional-manual-deployment-processes" class="hash-link" aria-label="Direct link to Traditional Manual Deployment Processes" title="Direct link to Traditional Manual Deployment Processes">​</a></h3><p>A manual deployment process consists of human-executed steps, like updating configuration files, copying files to production environments, and restarting servers.</p><p>In the past, manual deployments were common because automation tools were either unavailable or unsophisticated. Despite advances in automation, many companies still have outdated, manual deployment processes because of the time and effort required to adopt automation.</p><p>Two key factors prompted a movement away from manual deployment processes: speed and reliability.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="speed">Speed<a href="#speed" class="hash-link" aria-label="Direct link to Speed" title="Direct link to Speed">​</a></h4><p>One of the central issues with manual deployments is that they are time-consuming.</p><p>Firstly, there is usually a delay between the request for deployment and the start of the deployment. New commits sit idle in version control until the team responsible for deployment kicks off the deployment process. In some cases, developers must notify of new changes well before deployment dates. For example, TrueCar’s manual deployment strategy involved “Change Management tickets”, which each team had to file eight days before deployment.<sup id="fnref-2"><a href="#fn-2" class="footnote-ref">2</a></sup></p><p><img loading="lazy" alt="Manual deployment delay" src="/assets/images/manual-deployment-delay-a71675144ea3bbac0e57bd25bca6a67f.png" width="900" height="182" class="img_ev3q"></p><p>Once the deployment process commences, sometimes a long series of manual tasks are required to bring the code to production. This includes running scripts, checking code quality, and monitoring progress.<sup id="fnref-3"><a href="#fn-3" class="footnote-ref">3</a></sup> If there are multiple teams responsible for different parts of the deployment process, they need to coordinate their efforts, causing additional delays.</p><p><img loading="lazy" alt="Waterfall delays" src="/assets/images/waterfall-delays-ec9255b8857f3ad5f7779211dff22d05.png" width="900" height="394" class="img_ev3q"></p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="reliability">Reliability<a href="#reliability" class="hash-link" aria-label="Direct link to Reliability" title="Direct link to Reliability">​</a></h4><p>The second major pitfall of manual deployments is that they are error-prone. Firstly, humans are bad at performing rote activities in a consistent, reliable manner, leading to errors when configuring servers, setting up environments, and performing tests.</p><p>In addition to inconsistent administration of deployment steps, manual deployments are often run from inconsistent environments. Traditionally, manual deployments do not utilize a centralized system to build, test, and deploy developers&#x27; code. Instead, developers build and test applications on their local machines, each potentially having operating systems and environments that are different from one another and, by extension, the production environment.<sup id="fnref-4"><a href="#fn-4" class="footnote-ref">4</a></sup> As a result, the application may function correctly when a developer tests it locally, but not in production.</p><p><img loading="lazy" alt="Without build server" src="/assets/images/without-build-server-69c0dc50a674e0ff1f52143821499a51.png" width="900" height="469" class="img_ev3q"></p><p>Still, there are some useful aspects to traditional manual deployment processes. For example, requiring human intervention can be a useful safety check against deploying buggy or low-quality code.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="automated-deployment-processes">Automated Deployment Processes<a href="#automated-deployment-processes" class="hash-link" aria-label="Direct link to Automated Deployment Processes" title="Direct link to Automated Deployment Processes">​</a></h3><p>Over time, many companies began to introduce automation into their deployment process. An automated deployment process is commonly called a deployment pipeline. A deployment pipeline runs in a repeatable, consistent manner, resulting in faster and more reliable deployments.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="speed-1">Speed<a href="#speed-1" class="hash-link" aria-label="Direct link to Speed" title="Direct link to Speed">​</a></h4><p>The automation starts with version control. In automated deployments, version control systems are more than code storage locations: they plug directly into deployment pipelines. When a commit is made to a repository, the version control system can automatically trigger the deployment pipeline. This eliminates delays between deployment requests and pipeline initiation.</p><p><img loading="lazy" alt="Manual vs automated deployment" src="/assets/images/manual-vs-automated-deployment-93867505e26cb552a0d7c4761c3692d5.png" width="900" height="328" class="img_ev3q"></p><p>Deployment pipelines that fully automate all steps from source through production can drastically shorten the time between release cycles. For example, once TrueCar switched to a fully automated pipeline, they transitioned from a “burdensome weekly release cycle to deploying code up to 100 times per week”.<sup id="fnref-5"><a href="#fn-5" class="footnote-ref">5</a></sup></p><p><img loading="lazy" alt="Fast release cycle" src="/assets/images/fast-release-cycle-4ede50d42602301c9b5ece6116e23882.png" width="900" height="358" class="img_ev3q"></p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="reliability-1">Reliability<a href="#reliability-1" class="hash-link" aria-label="Direct link to Reliability" title="Direct link to Reliability">​</a></h4><p>Automated deployment processes also ensure greater reliability by eliminating the need for human intervention and integrating tests and quality checks directly into the pipeline. Unlike manual deployments, automated deployment tasks are executed consistently; there is no chance of “forgetting” to perform a task. For example, automating testing consistently ensures bugs are identified early on.</p><p>Moreover, deployment pipelines address the environmental inconsistency issues found in classic manual deployments. They typically use dedicated machines, like a <strong>build server</strong>, to automatically carry out pipeline jobs. This eliminates the &quot;it works on my machine&quot; syndrome that is all too common in traditional manual deployments. If the code doesn’t work on the build server, it won&#x27;t make it to production.</p><p><img loading="lazy" alt="With build server" src="/assets/images/with-build-server-c92513ea1b58918ad7a044bb6a6a9733.png" width="900" height="325" class="img_ev3q"></p><p>While automated deployment pipelines offer many advantages, transitioning from manual to automated deployments can be difficult. Resistance to change and extensive planning are common hurdles for many companies,<sup id="fnref-6"><a href="#fn-6" class="footnote-ref">6</a></sup> and setting up deployment pipelines can be complex and demanding, as we’ll see later.</p><p>When introducing automation into their deployment processes, companies are typically striving to meet at least one of the following objectives: continuous integration, continuous delivery, and continuous deployment.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="3-cicd-pipelines">3. CI/CD Pipelines<a href="#3-cicd-pipelines" class="hash-link" aria-label="Direct link to 3. CI/CD Pipelines" title="Direct link to 3. CI/CD Pipelines">​</a></h2><p>As a whole, CI/CD refers to the process of <em>continuously</em> integrating code changes into a central repository and moving them closer to production. CI/CD can be broken down into a few parts.</p><ol><li><strong>Continuous Integration (CI)</strong> is the practice of regularly merging code into the main branch of a central repository after the code is tested and built.</li><li><strong>Continuous Delivery (CD)</strong> extends upon continuous integration by continuously taking the new build and preparing it for release.<sup id="fnref-7"><a href="#fn-7" class="footnote-ref">7</a></sup></li><li><strong>Continuous Deployment</strong> is the hallmark of a well-established CI/CD system: builds are immediately released into production.<sup id="fnref-8"><a href="#fn-8" class="footnote-ref">8</a></sup></li></ol><p><img loading="lazy" alt="Ci cd cd" src="/assets/images/ci-cd-cd-df4221eca651e42bfdd9ab01a4e4d925.png" width="900" height="552" class="img_ev3q"></p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="stages-of-a-cicd-pipeline">Stages of a CI/CD Pipeline<a href="#stages-of-a-cicd-pipeline" class="hash-link" aria-label="Direct link to Stages of a CI/CD Pipeline" title="Direct link to Stages of a CI/CD Pipeline">​</a></h3><p>A deployment pipeline is essential for delivering code changes from development to production. Although there is no one-size-fits-all pipeline, they are typically broken up into four stages:<sup id="fnref-9"><a href="#fn-9" class="footnote-ref">9</a></sup></p><ol><li><p>The <strong>Source</strong> stage connects the pipeline to a repository hosting platform such as GitHub. Specified triggers such as opening a pull request or merging into main will initiate the pipeline.<sup id="fnref-10"><a href="#fn-10" class="footnote-ref">10</a></sup></p></li><li><p>The <strong>Test</strong> stage executes tests against the updated application to ensure code quality and functionality. Standard forms of testing include static code analysis, unit testing, and integration testing. Static code analysis checks for stylistic issues and basic programmatic vulnerabilities; tools include ESLint and RuboCop. Unit testing verifies the functionality of code components individually; tools include Jest and RSpec. Integration testing confirms proper interactions between application components; tools include Cypress and Selenium.</p></li><li><p>The <strong>Build</strong> stage bundles the updated source code with its dependencies into a single deployable artifact; tools include Webpack and Docker.</p></li><li><p>The <strong>Deployment</strong> stage pushes the built artifact to one or more environments. Typically, this includes a Staging (Pre-Production) environment used by QA teams to review the application and give approval, as well as a Production environment that is accessible to end users and represents the final outcome of the deployment process. Examples of deployment destinations are Amazon Web Services (AWS) Fargate and Google Cloud Run.</p></li></ol><p><img loading="lazy" alt="Pipeline stages" src="/assets/images/pipeline-stages-ceaa015ddbcb5e23af354d3bdabbf122.png" width="900" height="313" class="img_ev3q"></p><p>Most deployment pipelines incorporate the stages outlined above. However, as companies adopt continuous integration, delivery, and deployment practices to different extents, they must consider a new tradeoff: how to balance safety with velocity.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="4-balancing-safety-and-velocity">4. Balancing Safety and Velocity<a href="#4-balancing-safety-and-velocity" class="hash-link" aria-label="Direct link to 4. Balancing Safety and Velocity" title="Direct link to 4. Balancing Safety and Velocity">​</a></h2><p>Practitioners of automated deployment usually need to make a tradeoff. A highly automated process gets code to production fast, but it may increase the likelihood of bugs entering production. On the flip side, a safer deployment process with more manual checks can reduce velocity. Teams can make a number of decisions to optimize the location of their deployment pipeline on a spectrum of balancing safety with velocity.</p><ol><li><strong>Branching Strategy</strong>: Traditional feature branching workflows such as Github Flow prioritize safety by reducing the risk of untested code being pushed to main. In contrast, trunk-based development prioritizes speed by encouraging direct commits to main.<sup id="fnref-11"><a href="#fn-11" class="footnote-ref">11</a></sup> However, if a bug is introduced in a trunk-based development workflow, it may necessitate a rollback to restore the code to its previous state.</li></ol><p><img loading="lazy" alt="Branching strategies" src="/assets/images/branching-strategies-156b6c269cc8d042379e797cd97bc11d.png" width="900" height="589" class="img_ev3q"></p><ol start="2"><li><strong>Merging Strategy</strong>: Deployment workflows can either automate the merging of pull requests when it passes status checks or require a manual merging process by a team member. Although auto-merging can speed up the pipeline, it introduces the risk of merging code that has not undergone adequate testing and review.</li></ol><p><img loading="lazy" alt="Auto merge" src="/assets/images/auto-merge-178e075e3a4193b6539abf060f236f2c.png" width="900" height="235" class="img_ev3q"></p><ol start="3"><li><strong>Staging Environment</strong>: Teams continuously deploy code to production or first deploy to a staging environment. In the case of continuous deployment, code that passes status checks is deployed straight to production without manual approval. This allows teams to deliver updates to end users quickly but increases the likelihood that production-time adjustments may need to be performed, such as rolling back to a previous deployment.</li></ol><p>To summarize, companies can enhance the speed of their CI/CD pipeline by implementing a trunk-based development workflow, automating code merging, and continuously deploying code. Alternatively, they can improve deployment safety by following a feature-branch workflow, mandating human code reviews before merging, and deploying to a staging environment before deploying to production.</p><p><img loading="lazy" alt="Safety velocity spectrum" src="/assets/images/safety-velocity-spectrum-df89331c76350a9a4e173e593d580b21.png" width="900" height="351" class="img_ev3q"></p><p>While CI/CD pipelines can be adapted to meet different goals in terms of speed and safety, they can also be adapted to support different application architectures, such as monoliths and microservices.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="5-cicd-for-monoliths-and-microservices">5. CI/CD for Monoliths and Microservices<a href="#5-cicd-for-monoliths-and-microservices" class="hash-link" aria-label="Direct link to 5. CI/CD for Monoliths and Microservices" title="Direct link to 5. CI/CD for Monoliths and Microservices">​</a></h2><p>There is no universal CI/CD pipeline that suits every scenario. To understand why CI/CD pipelines vary for monoliths and microservices, we must examine a few fundamental differences between the two.</p><p>A monolith is a single unit containing tightly-coupled components. A microservices architecture consists of independent, loosely coupled services distributed across the network. The monolith has historically been the dominant approach to building applications, but this has shifted toward microservices out of a need for agility and scalability. To understand how CI/CD pipelines differ for monoliths and microservices, we will first explore the differences in the architectures themselves.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="different-deployment-methods">Different Deployment Methods<a href="#different-deployment-methods" class="hash-link" aria-label="Direct link to Different Deployment Methods" title="Direct link to Different Deployment Methods">​</a></h3><p>For monoliths, the entire codebase is packaged into a single executable file or directory that is deployed to production.<sup id="fnref-12"><a href="#fn-12" class="footnote-ref">12</a></sup> In contrast, microservices are deployed as smaller, independent units.<sup id="fnref-13"><a href="#fn-13" class="footnote-ref">13</a></sup> Due to their size, microservices can be packaged, tested, and deployed much more efficiently than a monolith, enabling small, frequent updates to be made. Furthermore, microservices are fully decoupled so each service can be deployed on its own schedule without impacting the others.</p><p>Consider three services: a Payment, Inventory, and Notification Service. Deployments of each service could take place on different days of the week:</p><p><img loading="lazy" alt="Releasing microservices" src="/assets/images/releasing-microservices-390e7dc236e831c6ea92b390ba94cde1.png" width="900" height="367" class="img_ev3q"></p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="different-communication-methods">Different Communication Methods<a href="#different-communication-methods" class="hash-link" aria-label="Direct link to Different Communication Methods" title="Direct link to Different Communication Methods">​</a></h3><p>All components of a monolith run within the same application. As a result, the application’s modules <strong>communicate with function calls</strong>. In contrast, microservices <strong>communicate remotely with network calls</strong> (e.g. using HTTP). Unlike function calls, which are fast and reliable, network calls are susceptible to latency and unreliability. As we’ll discuss in a bit, these varying communication styles influence testing techniques for a CI/CD pipeline.</p><p><img loading="lazy" alt="Monolith microservices" src="/assets/images/monolith-microservices-3d02baa5cbf355d088098265349f3747.png" width="900" height="283" class="img_ev3q"></p><p>The distinct traits of microservices have implications for their CI/CD pipelines. Two defining characteristics of microservice architectures are their independent deployments and network-based communication methods. These two characteristics introduce two corresponding challenges for microservice-based CI/CD pipelines: managing pipelines for many microservices and conducting inter-service testing across the network.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="6-cicd-challenges-with-microservices">6. CI/CD Challenges with Microservices<a href="#6-cicd-challenges-with-microservices" class="hash-link" aria-label="Direct link to 6. CI/CD Challenges with Microservices" title="Direct link to 6. CI/CD Challenges with Microservices">​</a></h2><p>In this section, we’ll explore the specific challenges faced by CI/CD pipelines for microservices.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="pipeline-management-difficulties">Pipeline Management Difficulties<a href="#pipeline-management-difficulties" class="hash-link" aria-label="Direct link to Pipeline Management Difficulties" title="Direct link to Pipeline Management Difficulties">​</a></h3><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="the-many-pipeline-problem">The Many-Pipeline Problem<a href="#the-many-pipeline-problem" class="hash-link" aria-label="Direct link to The Many-Pipeline Problem" title="Direct link to The Many-Pipeline Problem">​</a></h4><p>One approach to fully decoupling microservice deployments is to attach an individual CI/CD pipeline to each service. Since microservice teams are usually autonomous, it is common for teams to build their own pipelines. This gives each team full control of the pipeline and its stages.</p><p><img loading="lazy" alt="Many pipelines" src="/assets/images/many-pipelines-0fccbe18b05fc2d9f26cd118f04af3ed.png" width="900" height="472" class="img_ev3q"></p><p>However, this many-pipeline approach adds complexity. There are multiple pipelines to maintain, along with their associated YAML files, scripts, and library versions. For example, when Expedia experienced an “explosion in the number of CI/CD pipelines”, the engineering teams found that they were “constantly needing to update” the pipelines for each microservice.<sup id="fnref-14"><a href="#fn-14" class="footnote-ref">14</a></sup></p><p>Furthermore, while microservices usually have decentralized teams, there still often exists a central team overseeing the pipelines.<sup id="fnref-15"><a href="#fn-15" class="footnote-ref">15</a></sup> This central team may struggle to keep up with the specifics of building, testing, and deploying each microservice. Consequently, it can be challenging to quickly make system-wide adjustments, such as rolling back a buggy microservice that has caused issues in the production environment.<sup id="fnref-16"><a href="#fn-16" class="footnote-ref">16</a></sup></p><p>To ease the burden of managing deployment pipelines for tens or hundreds of microservices, modularization techniques have emerged.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="the-shared-step-solution">The Shared Step Solution<a href="#the-shared-step-solution" class="hash-link" aria-label="Direct link to The Shared Step Solution" title="Direct link to The Shared Step Solution">​</a></h4><p>One solution for modularizing CI/CD pipelines across microservices is to reuse steps for different microservice pipelines. These shared steps could come in the form of shell scripts, reusable Docker images, repositories or libraries, or YAML templates.</p><p><img loading="lazy" alt="Shared segments" src="/assets/images/shared-segments-473c8545895db0b7c8659298e2c70d0c.png" width="900" height="472" class="img_ev3q"></p><p>This approach can help eliminate redundancies across pipelines, keeping them “DRY”.<sup id="fnref-17"><a href="#fn-17" class="footnote-ref">17</a></sup> Shared libraries prove particularly useful for microservices that have distinct deployment requirements but still share some common elements like utility functions and customized steps.</p><p>However, there are some major downsides to this approach. For one, it still requires bootstrapping and maintaining an individual pipeline for each microservice, and the shared pipeline steps themselves need to be maintained. Furthermore, this approach frequently results in version conflicts, where a shared step may contain a library that is compatible with certain microservices but not with others.<sup id="fnref-18"><a href="#fn-18" class="footnote-ref">18</a></sup></p><p>Let’s look at a different strategy that mitigates some of these complications.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="the-single-parameterized-pipeline-solution">The Single, Parameterized Pipeline Solution<a href="#the-single-parameterized-pipeline-solution" class="hash-link" aria-label="Direct link to The Single, Parameterized Pipeline Solution" title="Direct link to The Single, Parameterized Pipeline Solution">​</a></h4><p>The former approach assumes that each microservice must have its own dedicated CI/CD pipeline. An alternative approach is to create a single, reusable, parameterized pipeline that is passed context whenever it is executed. This means that the pipeline is flexible: instead of linking pipelines to fixed repository URLs, testing commands, and configuration file entry points, these values can be configurable for each service. Adding a new microservice to the pipeline is simply a matter of filling in these parameters.<sup id="fnref-19"><a href="#fn-19" class="footnote-ref">19</a></sup></p><p><img loading="lazy" alt="Shared pipeline" src="/assets/images/shared-pipeline-2fbcee96cae3fb6a6a9dd3fec776c526.png" width="900" height="398" class="img_ev3q"></p><p>While this single-pipeline approach can simplify building and maintaining CI/CD pipelines, it may not be the best fit for every team. To make it work, there must be a certain degree of uniformity in terms of how each service is built, tested, and deployed. For example, every microservice might need to be deployed to the same Kubernetes cluster. For microservices with more heterogeneous deployment requirements, a different approach may be needed.</p><p>Along with issues of managing CI/CD pipelines for microservices, there are also unique challenges with testing microservices.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="microservice-testing-challenges">Microservice Testing Challenges<a href="#microservice-testing-challenges" class="hash-link" aria-label="Direct link to Microservice Testing Challenges" title="Direct link to Microservice Testing Challenges">​</a></h3><p>Testing microservices and their interactions is essential for ensuring that the system functions correctly, but it can be challenging due to their distributed nature.<sup id="fnref-20"><a href="#fn-20" class="footnote-ref">20</a></sup> Unlike monolithic applications that run as a single entity, microservices are split across a network, so any tests that involve multiple services require making network calls. Consequently, testing strategies that were applied to monolithic applications may need to be reconsidered for microservices. Despite this challenge, it is crucial to test microservices in isolation, together, and as a whole system to ensure their proper functioning.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="solutions-for-testing-microservices">Solutions for Testing Microservices<a href="#solutions-for-testing-microservices" class="hash-link" aria-label="Direct link to Solutions for Testing Microservices" title="Direct link to Solutions for Testing Microservices">​</a></h4><p>There are several techniques available for testing at different levels of granularity. Here are some of the essential ones:<sup id="fnref-21"><a href="#fn-21" class="footnote-ref">21</a></sup></p><ol><li><strong>Unit Testing</strong> involves testing atomic units of a single service, such as its functions or classes, without relying on other services. However, it does not verify the interactions between services. Any services required for a unit test are mocked.</li></ol><p><img loading="lazy" alt="Unit mock testing" src="/assets/images/unit-mock-testing-900d19caafda67edb78c877df0648053.png" width="900" height="330" class="img_ev3q"></p><ol start="2"><li><p><strong>Integration Testing</strong> involves making network calls to test multiple services functioning together as a single subsystem. This technique may not be as precise as unit testing, but it can validate the larger behavior of whole subsystems. Integration Testing does not typically test the system as a whole.</p></li><li><p><strong>On-Demand Staging Environments</strong> replicate production conditions and include all the microservices in the system. Although not a formal testing strategy, developers can use staging environments to test the system end-to-end, without getting bogged down in the details of each service and inter-service communications. However, staging environments can be resource-intensive.</p></li></ol><p><img loading="lazy" alt="Integration vs staging testing" src="/assets/images/integration-vs-staging-testing-6f5c24650bcd59e7dd4293215ae7ebec.png" width="900" height="405" class="img_ev3q"></p><p>In practice, a comprehensive testing strategy will usually incorporate a combination of these testing strategies in order to increase confidence and test coverage.</p><p>Development teams using a manual deployment process for microservices might be looking to reap the benefits of automated deployments. One option development teams may consider is to build their own CI/CD pipeline</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="7-manually-building-a-cicd-pipeline-for-microservices">7. Manually Building a CI/CD Pipeline for Microservices<a href="#7-manually-building-a-cicd-pipeline-for-microservices" class="hash-link" aria-label="Direct link to 7. Manually Building a CI/CD Pipeline for Microservices" title="Direct link to 7. Manually Building a CI/CD Pipeline for Microservices">​</a></h2><p>Building a CI/CD pipeline from scratch can be time-consuming and difficult, especially if it needs to handle the inherent complexities of a microservices architecture. Smaller teams with limited experience with cloud infrastructure and automation may struggle to architect a robust pipeline. They might also lack the staff and expertise to maintain and optimize it. The following is an example list of tasks for setting up a pipeline on AWS (we definitely don’t expect you to read everything, though you’re welcome to).</p><p><img loading="lazy" alt="Building-a-pipeline" src="/assets/images/building-a-pipeline-435c403dffac99d5f4edb60fe04f4b48.png" width="900" height="669" class="img_ev3q"></p><p>Instead of investing significant time and effort into this project, teams may choose to leverage existing CI/CD solutions to simplify the process.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="8-existing-solutions">8. Existing Solutions<a href="#8-existing-solutions" class="hash-link" aria-label="Direct link to 8. Existing Solutions" title="Direct link to 8. Existing Solutions">​</a></h2><p>Existing solutions typically fall into two categories: DIY solutions and commercial solutions.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="diy-solutions">DIY Solutions<a href="#diy-solutions" class="hash-link" aria-label="Direct link to DIY Solutions" title="Direct link to DIY Solutions">​</a></h3><p>For organizations with more complex CI/CD pipeline setups, DIY solutions might be the best fit. There are many free open-source DIY CI/CD tools such as Jenkins, Ansible, Gitlab, and Tekton. These tools offer a high level of customization and control, allowing the tool to be tailored to a specific use case. For example, Jenkins achieves this customizability through its extensive plugin library.<sup id="fnref-22"><a href="#fn-22" class="footnote-ref">22</a></sup></p><p>Many DIY tools also allow for pipeline modularization and reusability. Jenkins accomplishes pipeline modularization through shared libraries while Tekton allows for the reusability of different subcomponents, such as tasks and pipelines.<sup id="fnref-23"><a href="#fn-23" class="footnote-ref">23</a></sup></p><p>While DIY solutions like Jenkins and Tekton offer a high degree of customization, they do require users to have a certain level of expertise in the relevant technologies. This means that teams with less experience in CI/CD may find them challenging to use, as they require users to make decisions about plugins, integrations, and deployment options. For example, with Jenkins, users must have knowledge of relevant plugins and be comfortable maintaining their own infrastructure. Likewise, Tekton requires experience with Kubernetes to set up and use effectively.</p><p>While companies with CI/CD expertise might be equipped to build customized pipelines, less established teams might reach for a Software as a Service (SaaS) product to help manage their CI/CD needs.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="commercial-solutions">Commercial Solutions<a href="#commercial-solutions" class="hash-link" aria-label="Direct link to Commercial Solutions" title="Direct link to Commercial Solutions">​</a></h3><p>There are various commercial CI/CD pipelines available such as Codefresh, Semaphore, CircleCI, and AWS CodePipeline. While not typically as flexible as open-source tools, these solutions do generally provide a degree of customization. For instance, YAML configuration files are commonly used to configure pipelines and their stages.</p><p>Some commercial CI/CD solutions offer pipeline modularization and reusability. With CodeFresh, a single pipeline can be linked to multiple repositories, or “triggers”. Environment variables associated with each trigger can then be passed to the pipeline at execution time. Meanwhile, Semaphore offers a “monorepo” approach, enabling multiple applications stored in a single repository to access the same CI/CD pipeline.</p><p>Some commercial CI/CD solutions provide microservice-specific testing solutions. For example, in order to test one service against other services, Codefresh allows the user to specify “sidecar containers” that will spin up during specified stages of the pipeline.</p><p>Commercial solutions are not suitable for the CI/CD needs of all teams. They are typically not as extensible as open-source solutions, making them unsuitable for certain use cases. And despite being generally easier to use than DIY tools, they usually still require setting up and configuring pipelines.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="a-solution-for-our-use-case">A Solution for Our Use Case<a href="#a-solution-for-our-use-case" class="hash-link" aria-label="Direct link to A Solution for Our Use Case" title="Direct link to A Solution for Our Use Case">​</a></h3><p>We wanted to build a tool for a specific use case: companies with a lower employee count that have embraced a containerized, microservices approach, seeking an uncomplicated solution for managing their CI/CD pipelines across their microservices.</p><p>While microservice architectures are commonly associated with large enterprises such as Netflix, some startups and small teams utilize a microservice-first approach. Startups that value fast feedback cycles often turn to microservice architectures as they allow for the release of incremental updates to microservices in isolation.<sup id="fnref-24"><a href="#fn-24" class="footnote-ref">24</a></sup> Furthermore, startups anticipating a need to scale might adopt microservices early on because small microservices are easier to scale independently than a giant monolith.<sup id="fnref-25"><a href="#fn-25" class="footnote-ref">25</a></sup></p><p>An example of this is Sortal, a digital asset management product built by a startup using microservices. Despite being a small application, Sortal still had “a lot of <!-- -->[deployment]<!-- --> processes to manage, especially for a small team.”<sup id="fnref-26"><a href="#fn-26" class="footnote-ref">26</a></sup> Sortal’s small team overcame this complexity by utilizing a centralized, automated pipeline that enabled them to continuously deploy their application. We sought to assist companies with similar profiles in managing their microservices architecture.</p><p>Our solution would make managing the deployment of multiple microservices easier by applying a single, reusable, pipeline to each of the user&#x27;s services. It would require minimal configuration by providing sensible default settings that meet the typical demands of a CI/CD pipeline. However, it would still accommodate different CI/CD workflows (varying branching, merging, and auto-deployment strategies).</p><p>Furthermore, unlike most commercial products, our solution would be open-source and fully self-hosted, allowing for complete control of code and data ownership. Lastly, it would provide options for testing and inspecting microservices at different levels of granularity.</p><p><img loading="lazy" alt="Comparison chart" src="/assets/images/comparison-chart-f453852abc3320f12278bdb2e73918be.png" width="900" height="425" class="img_ev3q"></p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="9-introducing-seamless">9. Introducing Seamless<a href="#9-introducing-seamless" class="hash-link" aria-label="Direct link to 9. Introducing Seamless" title="Direct link to 9. Introducing Seamless">​</a></h2><p>Seamless is an open-source CI/CD pipeline tool designed specifically for containerized microservices deployed to AWS Elastic Container Service (ECS) Fargate. It offers a user-friendly interface that is similar to many of the popular interfaces found in commercial solutions. Unlike other CI/CD pipelines, Seamless does not require user-defined scripting through a YAML file template for configuration. Instead, Seamless relies on a core set of default stages: Prepare, Code Quality, Unit Test, Build, Integration Test, Deploy to Staging, and Deploy to Production. This approach makes Seamless easy to use right out of the box. Through the interface, users simply provide the necessary commands needed to run each stage. In the following sections, we will explore the steps a user takes to install, set up, and run Seamless’s CI/CD pipeline on their microservices.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="installing-seamless">Installing Seamless<a href="#installing-seamless" class="hash-link" aria-label="Direct link to Installing Seamless" title="Direct link to Installing Seamless">​</a></h3><p>In order to install and deploy Seamless a user must have:</p><ul><li>An AWS account</li><li><code>npm</code> installed</li><li>The AWS CLI installed and configured</li><li>The AWS CDK command line tool installed</li></ul><p>To install the Seamless CLI, the user runs <code>npm install -g @seamless-cicd/seamless</code>. Global installation is required. Next, running <code>seamless init</code> will guide this person through a series of inputs needed to deploy Seamless. After completing the initialization process, executing <code>seamless deploy</code> will provision Seamless&#x27;s infrastructure on AWS and provide a URL to access the platform&#x27;s dashboard.</p><p><img loading="lazy" alt="Cli commands" src="/assets/images/cli-commands-fe1ad049e99f263e65ca66c07d426660.png" width="900" height="442" class="img_ev3q"></p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="using-seamless">Using Seamless<a href="#using-seamless" class="hash-link" aria-label="Direct link to Using Seamless" title="Direct link to Using Seamless">​</a></h3><p>After deploying Seamless’s infrastructure, the user can visit the dashboard and complete the pipeline setup process. They will provide the names of their production and staging environments (ECS clusters) so that Seamless knows where to deploy their microservices.</p><p><img loading="lazy" alt="Pipeline gif" src="/assets/images/pipeline-f682eb118a657249dff6b2f29ddaec8e.gif" width="3400" height="1284" class="img_ev3q"></p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="connecting-services-to-the-pipeline">Connecting Services to the Pipeline<a href="#connecting-services-to-the-pipeline" class="hash-link" aria-label="Direct link to Connecting Services to the Pipeline" title="Direct link to Connecting Services to the Pipeline">​</a></h4><p>Upon completing the setup of the pipeline, the user can create multiple services that will utilize the pipeline. The service setup process collects all the necessary information to run the pipeline, verify code functionality, and promote it to production.</p><p><img loading="lazy" alt="Service gif" src="/assets/images/service-e4443f96685afdfdfded5ac79db59652.gif" width="3400" height="1284" class="img_ev3q"></p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="running-the-pipeline">Running the Pipeline<a href="#running-the-pipeline" class="hash-link" aria-label="Direct link to Running the Pipeline" title="Direct link to Running the Pipeline">​</a></h4><p>Now the pipeline is ready to be activated. It can be triggered manually or by the version control changes:</p><ol><li>A pull request is opened (PR Open)</li><li>A commit is made on a pull request (PR Sync)</li><li>A pull request is merged (Commit to Main)</li></ol><p><img loading="lazy" alt="Pipeline triggers" src="/assets/images/pipeline-triggers-0429bb2437175f5069d0103239a8bbfc.png" width="900" height="492" class="img_ev3q"></p><p>Now that the pipeline is running, the user might want to view its progress.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="monitoring-the-pipeline">Monitoring the Pipeline<a href="#monitoring-the-pipeline" class="hash-link" aria-label="Direct link to Monitoring the Pipeline" title="Direct link to Monitoring the Pipeline">​</a></h4><p>Seamless’s UI displays live updates of both runs and stages, enabling users to stay informed of pipeline outcomes as runs and stages transition from “Idle” to “In Progress”, and ultimately to “Success” or “Failure”. Log data is updated live, making it easier to identify and troubleshoot errors when they occur.</p><p><img loading="lazy" alt="Pipeline run" src="/assets/images/pipeline-run-798w-dc2dbbe77e1557b3baaeede06e9e7506.gif" width="798" height="570" class="img_ev3q"></p><p>We will now shift the discussion toward the technical challenges we faced when building Seamless.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="10-architecture-overview">10. Architecture Overview<a href="#10-architecture-overview" class="hash-link" aria-label="Direct link to 10. Architecture Overview" title="Direct link to 10. Architecture Overview">​</a></h2><p>We’ll start with the fundamental challenges we had to address, provide a high-level overview of our core architecture, and then dive deeper into design decisions and tradeoffs.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="fundamental-challenges">Fundamental Challenges<a href="#fundamental-challenges" class="hash-link" aria-label="Direct link to Fundamental Challenges" title="Direct link to Fundamental Challenges">​</a></h3><p>When building our initial prototype, we focused on the fundamental problems that needed to be solved in order to build the core functionality of a CI/CD pipeline:</p><ul><li>Deciding how to model pipeline data, and selecting a database that we could run detailed queries on</li><li>Configuring code repositories to notify Seamless whenever code changes, and setting up a way to use those notifications as triggers to automatically start the pipeline</li><li>Finding a mechanism to monitor and control the pipeline’s execution flow, with the ability to store complex state</li><li>Determining how and where to execute the physical steps of each pipeline stage</li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="core-architecture">Core Architecture<a href="#core-architecture" class="hash-link" aria-label="Direct link to Core Architecture" title="Direct link to Core Architecture">​</a></h3><p>After some initial prototyping, we arrived at the architecture below, which shows the high-level flow of how a pipeline is triggered and executed. A backend server listens for webhooks from a code repository, retrieves pipeline information from a database, and starts the pipeline. The pipeline performs a series of tasks, including deploying the updated application to production.</p><p><img loading="lazy" alt="Architecture core simplified" src="/assets/images/architecture-core-simplified-282d33cd985715e40423ee3070393304.png" width="900" height="495" class="img_ev3q"></p><p>With an overall direction in mind, we decided to explore different options for each component of our core architecture.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="11-building-the-core-pipeline-functionality">11. Building the Core Pipeline Functionality<a href="#11-building-the-core-pipeline-functionality" class="hash-link" aria-label="Direct link to 11. Building the Core Pipeline Functionality" title="Direct link to 11. Building the Core Pipeline Functionality">​</a></h2><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="modeling-and-storing-data">Modeling and Storing Data<a href="#modeling-and-storing-data" class="hash-link" aria-label="Direct link to Modeling and Storing Data" title="Direct link to Modeling and Storing Data">​</a></h3><p>At the outset, we created a data model that served as the bedrock for the remainder of our application. It comprises four fundamental entities: Pipelines, Services, Runs, and Stages. As a reminder, smaller companies without dedicated teams for managing multiple disparate CI/CD pipelines can simplify their CI/CD management by using a single pipeline for multiple services. Subsequently, our data model establishes a one-to-many relationship between Pipelines and Services. Additionally, each Service can have many Runs and each Run can have many Stages.</p><p><img loading="lazy" alt="Data model" src="/assets/images/data-model-5faf3dca218ed44a480332d3ef0b29ac.png" width="900" height="241" class="img_ev3q"></p><p>At first, we considered using a NoSQL document store like DynamoDB to store our data. NoSQL document stores are optimized for speed, scalability, and storing unstructured data. However, given that our project does not involve high-frequency read or write operations, and our schema is fixed, we opted for PostgreSQL, a relational database. We rely on the Prisma ORM to streamline schema creation and migration, as well as data manipulation.</p><p>With our data model in place, we narrowed in on how we could automate the journey of code from source to production.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="automating-pipeline-runs">Automating Pipeline Runs<a href="#automating-pipeline-runs" class="hash-link" aria-label="Direct link to Automating Pipeline Runs" title="Direct link to Automating Pipeline Runs">​</a></h3><p>A key component of automated deployment pipelines is their ability to execute immediately when source code is modified. Webhooks are used to link user repositories to the pipeline:</p><p><img loading="lazy" alt="Webhook" src="/assets/images/webhook-wide-7a71faf51a6f7acdf3247c92301e190a.png" width="900" height="347" class="img_ev3q"></p><p>Seamless registers the webhooks using Github’s Octokit client. The flow from Webhook registration to pipeline initiation is as follows:</p><ol><li>Seamless creates a webhook in the user&#x27;s repository, utilizing GitHub&#x27;s Octokit client to authenticate and interact with their API.</li><li>The user makes an update to the source code.</li><li>GitHub sends a webhook to Seamless’s backend server.</li><li>The backend uses the payload of the webhook to identify the trigger and initiate the appropriate pipeline process.</li></ol><p><img loading="lazy" alt="Create webhook" src="/assets/images/create-webhook-c2653db7ff1ee4f29c10a89efd0a246c.png" width="900" height="373" class="img_ev3q"></p><p>However, running the entire deployment pipeline for every change would have compromised our goal of velocity. To overcome this challenge, we tailored our pipeline to three distinct triggers:</p><ol><li>Merge/Push to Main</li><li>Open Pull Request</li><li>Synchronize/Update Pull Request</li></ol><p>For pushes to the main branch, the entire pipeline is executed, whereas pull request opens and synchronizations only perform code quality checks and tests, without any intention of deployment:</p><p><img loading="lazy" alt="Trigger partial vs full run" src="/assets/images/trigger-partial-vs-full-run-44435ad8093ef23a1c1e8a583cd6eac8.png" width="900" height="289" class="img_ev3q"></p><p>With a system in place to trigger the pipeline, we moved on to building out the pipeline itself.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="managing-pipeline-execution">Managing Pipeline Execution<a href="#managing-pipeline-execution" class="hash-link" aria-label="Direct link to Managing Pipeline Execution" title="Direct link to Managing Pipeline Execution">​</a></h3><p><img loading="lazy" alt="Architecture core simplified taskmanager" src="/assets/images/architecture-core-simplified-taskmanager-e2fa543ba52d22665a6b1d2e4abf2b45.png" width="900" height="495" class="img_ev3q"></p><p>First, we needed to consider how to manage the execution flow of our pipeline. We aimed to avoid having a single fixed execution path for our pipeline, as the degree to which different companies&#x27; CI/CD workflows embrace automation can vary significantly. The execution path could differ depending on:</p><ol><li>What triggered it</li><li>User-configured settings, such as whether a staging environment is used</li><li>The success of tasks</li></ol><p>We wanted to build a system that would behave differently depending on these factors. We also wanted our system to keep track of the state of the pipeline as it ran so we could inform users of it.</p><p>Our initial approach to managing tasks was to use a job queue to run tasks in a linear manner. This did not suffice for our final use case. The job queue lacked built-in capabilities to model nonlinear execution paths taken by our pipeline. Furthermore, it did not provide a centralized way to track the status of the pipeline and its stages, nor could it guarantee that only one stage was executing at a time.</p><p>We also looked into event-driven architecture where each task would call the next, and there would be no manager. However, we felt that having a central place to manage state would make managing and debugging our pipeline easier.</p><p>Ultimately, we decided to use a state machine to orchestrate pipeline executions. The state machine model allowed us to describe the behavior of our pipeline by defining all possible states for each stage (such as Idle, Success, Fail, or In Progress), the transitions between these states, and the decisions along the way that could affect its execution flow.</p><p><img loading="lazy" alt="State machine example" src="/assets/images/state-machine-example-5ff53e99a78133adc36021acd57c00e6.png" width="900" height="338" class="img_ev3q"></p><p>One drawback to state machines was that defining states and transitions in advance would limit the ability to add new steps dynamically. As a result, the core logic of the pipeline would be unmodifiable once it is set up. We determined that this tradeoff was acceptable for our use case. Smaller organizations early in their adoption of microservices are more likely to have services with similar CI/CD requirements, resulting in a reduced need for customizability.</p><p>Next, we needed to determine how we would run our state machine. We knew the state machine would have varying usage patterns, depending on the team&#x27;s commit rate and other factors. To accommodate this flexibility, we opted for a serverless, pay-as-you-go infrastructure that could scale according to our users&#x27; needs.</p><p>AWS offers a serverless state machine service called Step Functions that integrates natively with other AWS services. As the Step Function progresses through the stages in our pipeline, it uses a context object to communicate pipeline status to our backend effectively.</p><p><img loading="lazy" alt="Step function definition" src="/assets/images/step-function-definition-8a6b79ce7baf2a6eee1a32d891d2f424.png" width="900" height="622" class="img_ev3q"></p><p>We also considered running the state machine directly on our backend servers, utilizing the XState JavaScript library to define the logic, but its lack of AWS integrations made it less suitable for our needs. Additionally, this approach may have introduced scaling challenges that were abstracted by using step functions.</p><p>At this point, we had a tool that would help us manage pipeline tasks, but we also needed to consider how to run the tasks themselves.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="running-tasks">Running Tasks<a href="#running-tasks" class="hash-link" aria-label="Direct link to Running Tasks" title="Direct link to Running Tasks">​</a></h3><p><img loading="lazy" alt="Architecture core simplified taskexecutors" src="/assets/images/architecture-core-simplified-taskexecutors-74b57ed3c776cc10f9debe349445d36d.png" width="900" height="495" class="img_ev3q"></p><p>A pipeline task comprises the set of operations that must be performed to fulfill the purpose of a given stage. In Seamless, a task is a Javascript program. Some of these programs run child processes that execute commands for cloning, building, and testing code, while others use the AWS SDK to perform deployment-related actions.</p><p><img loading="lazy" alt="Build task" src="/assets/images/build-task-0fd8183e9e6200301dd3df190864aef0.png" width="900" height="461" class="img_ev3q"></p><p>Now that we know what a task is, let’s look at the two infrastructure choices we had for running these tasks: virtual machines and containers.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="virtual-machines-or-containers">Virtual Machines or Containers<a href="#virtual-machines-or-containers" class="hash-link" aria-label="Direct link to Virtual Machines or Containers" title="Direct link to Virtual Machines or Containers">​</a></h4><p>To determine the appropriate infrastructure for running pipeline tasks, we examined the nature of the tasks themselves.</p><ol><li>Tasks are <strong>consistent</strong>: For every pipeline run, each task should operate in the same way.</li><li>Tasks are <strong>ephemeral</strong>: Once a task runs, it will not rerun until the next pipeline execution.</li><li>Tasks <strong>fluctuate with demand</strong>: Depending on the team&#x27;s commit rate and other factors, the frequency at which a task runs can vary over time.</li></ol><p>One approach we explored was having a dedicated build server running on a virtual machine (VM) to build, test, and deploy a user’s application. This fulfilled our need for a centralized, consistent environment to run tasks. Additionally, VMs also offer full hardware virtualization, providing strong isolation from other virtual machines running on the same host. However, the virtual machine approach had a few drawbacks:</p><ol><li><strong>Elasticity</strong>: Scaling VMs to meet the demands of the pipeline is slow because they take a few minutes to start.</li><li><strong>Resource-Intensive</strong>: VMs require significant resources since each virtualizes an entire operating system. Furthermore, the VM running the pipeline would need to be configured with all dependencies to run any pipeline tasks.</li></ol><p>To overcome the limitations of virtual machines, we explored alternative solutions and discovered that using containers to run steps in CI/CD pipelines is a prevalent industry trend.<sup id="fnref-27"><a href="#fn-27" class="footnote-ref">27</a></sup> Like a build server on a virtual machine, containers provide consistent environments for running tasks. However, unlike virtual machines, containers are more lightweight, meaning that they can more easily spin up and down automatically to match demand.</p><p><img loading="lazy" alt="Container vs vm" src="/assets/images/container-vs-vm-3fe5c4961603d87cc55787d91a93ba82.png" width="900" height="379" class="img_ev3q"></p><p>As our infrastructure was already hosted on AWS, we aimed to find an AWS-native way to run containers, and so decided to use Amazon’s Elastic Container Service (ECS).</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="managing-servers">Managing Servers<a href="#managing-servers" class="hash-link" aria-label="Direct link to Managing Servers" title="Direct link to Managing Servers">​</a></h4><p>Our next decision was whether to run containers in a serverless fashion with ECS Fargate or to have direct access to the virtual machines hosting the containers. While Fargate would reduce underlying server management overhead, it was not a feasible choice. We actually needed access to the underlying virtual machines in order to run Docker within our containers for tasks such as building services as images. Without access to the virtual machines, we couldn&#x27;t achieve this functionality. Consequently, we determined that running ECS on EC2, AWS’s virtual machine service, was the optimal solution for our specific requirements.</p><p>Since Step Functions natively integrates with other AWS services, we could trigger the ECS task containers (or, as we call them, Task Executors) directly from it, as the below diagram depicts:</p><p><img loading="lazy" alt="Task containers" src="/assets/images/task-containers-f0037d1debfe02d9e437cb4397e426ef.png" width="900" height="371" class="img_ev3q"></p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="overview-of-core-functionality">Overview of Core Functionality<a href="#overview-of-core-functionality" class="hash-link" aria-label="Direct link to Overview of Core Functionality" title="Direct link to Overview of Core Functionality">​</a></h3><p>Ultimately we settled on the following implementation for our core architecture:</p><ol><li>A change in the user’s Github repository sends a webhook to Seamless’s backend.</li><li>Seamless’s backend processes the webhook and fetches relevant information from Postgres to start the state machine.</li><li>A state machine running on Step Functions orchestrates the pipeline execution flow.</li><li>The state machine calls ECS task executors to run pipeline tasks.</li></ol><p><img loading="lazy" alt="Architecture core detailed" src="/assets/images/architecture-core-detailed-b265a671c133b4e9d2b14bd7aad7b619.png" width="900" height="495" class="img_ev3q"></p><p>Once we had built the structural foundation for the pipeline, we looked to expand our project further.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="12-improving-core-functionality">12. Improving Core Functionality<a href="#12-improving-core-functionality" class="hash-link" aria-label="Direct link to 12. Improving Core Functionality" title="Direct link to 12. Improving Core Functionality">​</a></h2><p>Once Seamless’ core functionality was working, users were able to automatically test, build, and deploy their microservices upon changes in version control. With our core pipeline in place, we decided to add features to make our CI/CD pipeline more robust and targeted toward microservices. Below is a more detailed diagram of our architecture, with improved functionality in place:</p><p><img loading="lazy" alt="Architecture improved simplified predeployment" src="/assets/images/architecture-improved-simplified-predeployment-971021a96d3eeae9153b2f5c28c97518.png" width="900" height="512" class="img_ev3q"></p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="realtime-dashboard-updates">Realtime Dashboard Updates<a href="#realtime-dashboard-updates" class="hash-link" aria-label="Direct link to Realtime Dashboard Updates" title="Direct link to Realtime Dashboard Updates">​</a></h3><p>In order to give the user the ability to detect and respond to pipeline issues as they occur, we implemented real-time updates that are sent to our dashboard.</p><p>We considered using client-side polling, where the client queries the API at regular intervals but ultimately decided against it because it generates unnecessary HTTP requests and might cause delays between backend and frontend updates. We decided to use WebSockets instead. The dashboard initiates a WebSockets connection to a Websockets API Gateway on the backend. Status updates and logs arriving on the backend are forwarded to the dashboard via the WebSockets connection persisted by the API Gateway.</p><p><img loading="lazy" alt="Polling vs websockets" src="/assets/images/polling-vs-websockets-97838a8ffa54973f2b800f0659c63d4a.png" width="900" height="510" class="img_ev3q"></p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="improvements-to-pre-deployment-tasks">Improvements to Pre-Deployment Tasks<a href="#improvements-to-pre-deployment-tasks" class="hash-link" aria-label="Direct link to Improvements to Pre-Deployment Tasks" title="Direct link to Improvements to Pre-Deployment Tasks">​</a></h3><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="sharing-data-among-containers">Sharing Data Among Containers<a href="#sharing-data-among-containers" class="hash-link" aria-label="Direct link to Sharing Data Among Containers" title="Direct link to Sharing Data Among Containers">​</a></h4><p>To minimize repeated work, we needed to ensure that multiple pipeline tasks could access the same files. For example, the Prepare Stage clones the source code so the Build Stage can package it into a Docker image later. To achieve this, we used the AWS EFS network file system, which is designed to be mounted to any number of EC2 instances or ECS containers. EFS scales automatically by providing the necessary storage without needing to specify the capacity in advance.</p><p>When each container is started, it is automatically mounted to a shared persistent Docker volume on EFS. The hash of the commit that triggered the current execution serves as the directory name for the source code, which prevents naming conflicts and enables pipeline executions from separate commits or services to occur in parallel. If two commits cause two concurrent pipeline executions, the files generated by either execution will not interfere with one another.</p><p><img loading="lazy" alt="Efs" src="/assets/images/efs-9638813e8061083a2d964cf3e40c7384.png" width="900" height="524" class="img_ev3q"></p><p>We also considered block storage. Although block storage presented some performance advantages, it was designed to be accessed from a singular virtual machine, making it unsatisfactory for our distributed task containers that were running across multiple VMs.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="integration-testing">Integration Testing<a href="#integration-testing" class="hash-link" aria-label="Direct link to Integration Testing" title="Direct link to Integration Testing">​</a></h4><p>Earlier, we presented integration testing as a key testing strategy for microservice architectures, where multiple microservices are tested together as a whole subsystem. To show an example, let’s examine two methods for performing integration tests for a new version of Service A against the latest versions of Service B and C.</p><p>One option is to test the new Service A against live, production instances of Service B and C, but this approach has a major drawback: any destructive calls made during testing could unintentionally alter the production system&#x27;s state or affect its performance.</p><p>Another approach is to spin up instances of Service B and C in an isolated test environment. Despite added complexity and additional resource requirements, this approach avoids the risks of interfering with production instances of services.</p><p><img loading="lazy" alt="Test vs prod environment" src="/assets/images/test-vs-prod-environment-18866b34f4b732318bcb37217735d218.png" width="900" height="360" class="img_ev3q"></p><p>To accomplish this, we leveraged Docker Compose, a service that facilitates container management and networking. The user provides a Docker Compose configuration file that specifies the dependency services required to run integration tests for Service A. During the integration testing phase, Docker Compose pulls the latest versions of the dependency services from a container registry and runs the integration tests.</p><p>This approach offers several benefits, including the ability to test in an environment that closely mirrors production and avoiding the risk of inadvertently affecting live data. Moreover, it aligns with the user&#x27;s existing workflow if they already use Docker Compose for local testing.</p><p><img loading="lazy" alt="Integration test" src="/assets/images/integration-test-9f85b583ccbaf4d38e51717aa694a7c9.png" width="900" height="599" class="img_ev3q"></p><p>So far, we have focused on tasks that occur pre-deployment. Now we will dive into tasks directly related to deploying services.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="improvements-to-deployment-related-tasks">Improvements to Deployment-Related Tasks<a href="#improvements-to-deployment-related-tasks" class="hash-link" aria-label="Direct link to Improvements to Deployment-Related Tasks" title="Direct link to Improvements to Deployment-Related Tasks">​</a></h3><p><img loading="lazy" alt="Architecture improved simplified deployment" src="/assets/images/architecture-improved-simplified-deployment-073912d99d1a128db5ad442572939f15.png" width="900" height="512" class="img_ev3q"></p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="manual-approval-of-staging-environments">Manual Approval of Staging Environments<a href="#manual-approval-of-staging-environments" class="hash-link" aria-label="Direct link to Manual Approval of Staging Environments" title="Direct link to Manual Approval of Staging Environments">​</a></h4><p>Most of Seamless’s pipeline executes in a fully automated fashion. However, most CI/CD workflows do not embrace full continuous deployment, so Seamless provides an optional staging environment from which the user could manually approve deployment to production.</p><p>There were two patterns we could use to link stages to one another:</p><ol><li>Proceed immediately to the next stage after one stage completes</li><li>Pause after a stage completes</li></ol><p>AWS Step Functions offers two analogous job invocation styles: “Synchronous” and “Wait for a Callback Token”. The Synchronous model was suitable for most stages because each stage should automatically start after the previous one finishes. However, if the user disables continuous deployment, the state machine should pause so the developer can perform quality checks on the staging environment. This second scenario was a good use case for Step Function’s Wait for a Callback Token pattern.</p><p><img loading="lazy" alt="Manual approval" src="/assets/images/manual-approval-f14ec9f277b51296276ff51e0dccc969.png" width="900" height="265" class="img_ev3q"></p><p>Even if a staging environment is used, there is still a possibility of faulty code reaching production. For this reason, we decided to implement rollbacks.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="rollbacks">Rollbacks<a href="#rollbacks" class="hash-link" aria-label="Direct link to Rollbacks" title="Direct link to Rollbacks">​</a></h4><p>New and small companies often prioritize speedy code releases, which can carry the risk of introducing errors or failures in the production environment. Rollbacks allow teams to restore a previous stable version of a service.</p><p>To enable rollbacks, we tag all Docker images with the git commit hash. Our UI displays all possible rollback images, giving users a choice of rollback targets. Instead of redeploying the entire system for a given rollback, each service can be rolled back independently, minimizing the impact on the overall deployment.</p><p><img loading="lazy" alt="Rollbacks" src="/assets/images/rollbacks-1fb09aa23daf9ca4da32ea03e3c71f2a.png" width="900" height="462" class="img_ev3q"></p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="automatic-deployment-of-fargate-clusters">Automatic Deployment of Fargate Clusters<a href="#automatic-deployment-of-fargate-clusters" class="hash-link" aria-label="Direct link to Automatic Deployment of Fargate Clusters" title="Direct link to Automatic Deployment of Fargate Clusters">​</a></h4><p>Since Seamless is targeted toward smaller teams that might lack experience deploying microservices, we built a feature that automatically deploys the user’s Docker images to a Fargate Cluster and implements service discovery using AWS Service Connect. This approach helps users get their services up and running in production quickly, as they only need to provide basic information about their service and its image. The feature can be used to set up both staging and production environments.</p><p>At this point, our core architecture looked like this:</p><p><img loading="lazy" alt="Architecture improved detailed" src="/assets/images/architecture-improved-detailed-88a9a7a5239cff7496efef7c614acbda.png" width="900" height="522" class="img_ev3q"></p><p>With our core functionality in place, we made Seamless a complete application by considering performance and scalability, security, notifications, and logging.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="13-beyond-the-core-pipeline">13. Beyond the Core Pipeline<a href="#13-beyond-the-core-pipeline" class="hash-link" aria-label="Direct link to 13. Beyond the Core Pipeline" title="Direct link to 13. Beyond the Core Pipeline">​</a></h2><p>There were a few additional infrastructural considerations and features remaining for us to review. Infrastructurally, we wanted to make Seamless more performant, scalable, and secure. We also wanted to add features that would make it easier for the user to monitor their pipeline, including notifications and log streaming.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="designing-for-performance-and-scale">Designing for Performance and Scale<a href="#designing-for-performance-and-scale" class="hash-link" aria-label="Direct link to Designing for Performance and Scale" title="Direct link to Designing for Performance and Scale">​</a></h3><p>Even though Seamless is designed for smaller companies, we designed our infrastructure to support the growth of such companies, whether it be adding more microservices or hiring more developers and making more commits. For instance, we evaluated the possibility of many changes being made to many microservices at once. Consider a scenario where ten microservices each initiate five new pull requests simultaneously; in such a case, Seamless&#x27;s infrastructure would have to contend with managing fifty concurrent pipeline executions. To tackle this challenge, we developed Seamless to manage high volumes of pipeline executions.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="parallel-execution-of-state-machines">Parallel Execution of State Machines<a href="#parallel-execution-of-state-machines" class="hash-link" aria-label="Direct link to Parallel Execution of State Machines" title="Direct link to Parallel Execution of State Machines">​</a></h4><p>Firstly, Seamless enables parallel execution of state machines by utilizing separate instances of AWS Step Functions. This allows for concurrent execution, enabling different microservices to use the shared pipeline simultaneously.</p><p><img loading="lazy" alt="Parallel execution" src="/assets/images/parallel-execution-22a755600801c2a9cd6861263c5c6d10.png" width="900" height="337" class="img_ev3q"></p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="serverless-backend">Serverless Backend<a href="#serverless-backend" class="hash-link" aria-label="Direct link to Serverless Backend" title="Direct link to Serverless Backend">​</a></h4><p>Seamless’s backend processes all status updates and logs generated by the pipeline. If there are many concurrent pipeline runs, the backend server could receive a high load of logs and status updates. As a result, we host our containerized backend on AWS’s serverless container engine, ECS Fargate to spin up as many containers as needed in response to demand, without sacrificing performance. We set up a load balancer to evenly distribute traffic among these containers.</p><p><img loading="lazy" alt="Serverless backend" src="/assets/images/serverless-backend-6655bf46f7fd1d90c1863018900eb29a.png" width="900" height="350" class="img_ev3q"></p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="basic-security">Basic Security<a href="#basic-security" class="hash-link" aria-label="Direct link to Basic Security" title="Direct link to Basic Security">​</a></h3><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="oauth">OAuth<a href="#oauth" class="hash-link" aria-label="Direct link to OAuth" title="Direct link to OAuth">​</a></h4><p>Seamless needs secure access to the user’s Github account to perform authorized actions, such as configuring webhooks and cloning their private repositories. To avoid exposing user credentials to Seamless, Seamless retrieves an access token using Github’s OAuth implementation. The flow looks like this:</p><ol><li>When a user logs in to Seamless, they authenticate with Github, which sends back a temporary code.</li><li>The user (client) passes that code to Seamless’s backend, which proxies the code to GitHub.</li><li>Github responds with an access token, which Seamless’s backend sends to the client.</li></ol><p>The access token generated during the OAuth flow can then be used by Seamless’s backend to:</p><ol><li>Configure webhooks on the user’s behalf.</li><li>Clone the user’s repositories during state machine execution.</li></ol><p><img loading="lazy" alt="Oauth flow" src="/assets/images/oauth-flow-c92f9c3272238b6832411243d8fcffbf.png" width="900" height="430" class="img_ev3q"></p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="private-subnets">Private Subnets<a href="#private-subnets" class="hash-link" aria-label="Direct link to Private Subnets" title="Direct link to Private Subnets">​</a></h4><p>We also wanted to prevent direct network access to Seamless’s infrastructure, aside from its public-facing API. As a result, we provisioned most of Seamless’s infrastructure in private subnets so they can’t accept incoming network traffic. In case a developer needs to interact with resources in private subnets, such as their relational database or Redis cache, we deploy a bastion host in a public subnet that a developer can SSH into.</p><p><img loading="lazy" alt="Private subnet" src="/assets/images/private-subnet-7d7d22530969881279275e7a5778cba7.png" width="900" height="486" class="img_ev3q"></p><p>Next, let’s look into a few ways Seamless assists in monitoring pipeline executions.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="logging">Logging<a href="#logging" class="hash-link" aria-label="Direct link to Logging" title="Direct link to Logging">​</a></h3><p>If a developer or maintainer were deploying their application manually, they would be able to see logs output from their commands in realtime. For an automated CI/CD pipeline, displaying logs to the user is key to proactively monitoring problems, resolving build and deployment failures, and analyzing test reports.</p><p>To integrate logging into Seamless, we first needed a system to capture logs from all task containers. We sought a storage mechanism capable of quickly processing large volumes of logs, and so decided to use a Redis cache (specifically, AWS ElastiCache) due to its high-speed, in-memory data storage capabilities.</p><p>We needed to display logs in chronologically sorted order. As a result, we decided to use sorted sets to insert logs in sorted order, eliminating the need for sorting when reading logs. Incoming log streams are sent over WebSockets to the dashboard, where they are finally displayed.</p><p><img loading="lazy" alt="Logging service" src="/assets/images/logging-service-69df951a3b305fc03d444000ff5dc267.png" width="900" height="386" class="img_ev3q"></p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="notifications">Notifications<a href="#notifications" class="hash-link" aria-label="Direct link to Notifications" title="Direct link to Notifications">​</a></h3><p>Engineering teams need to stay up-to-date with pipeline execution and quickly address any issues that arise. While users could already monitor their pipeline through the dashboard, we also added notification functionality to Seamless. Seamless offers integration with AWS Simple Notification Service (SNS), allowing for notifications to be sent via email, Slack, and PagerDuty.</p><p><img loading="lazy" alt="Notifications" src="/assets/images/notifications-b8f8f2e97b6f840f88fe243871538dd1.png" width="900" height="435" class="img_ev3q"></p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="14-conclusion--future-work">14. Conclusion &amp; Future Work<a href="#14-conclusion--future-work" class="hash-link" aria-label="Direct link to 14. Conclusion &amp; Future Work" title="Direct link to 14. Conclusion &amp; Future Work">​</a></h2><p>Now that we’ve discussed Seamless’s architecture in depth, let’s put it all together:</p><ol><li>When the source code is updated, GitHub sends a webhook to an API Gateway.</li><li>An Express.js backend running in an ECS Fargate cluster receives the webhook through an HTTP API Gateway.</li><li>The backend retrieves pipeline information from a PostgreSQL database and sends it to the state machine to initiate the pipeline.</li><li>The state machine executes each pipeline task in a container in ECS, which can share data via a mounted volume on Elastic File System (EFS) and access the Elastic Container Registry for pushing or pulling required images.</li><li>The updated source code is deployed to staging and production Fargate clusters.</li></ol><p>During the pipeline run, the state machine sends status updates to the backend for storage in the database, and to users via SNS. The task containers send logs to the backend to be inserted into a Redis log cache. The backend sends both status updates and logs to the frontend dashboard via a WebSockets connection maintained by the API Gateway.</p><p><img loading="lazy" alt="Architecture final" src="/assets/images/architecture-final-84fb0d0d780977955dcaa9f94fdb1acb.png" width="900" height="677" class="img_ev3q"></p><p>We narrowed down the scope of Seamless for Node-based containerized microservices running on ECS Fargate with similar build, test, and deployment requirements. However, going forward, there are additional features we would like to include and improvements we would like to make to our current implementation.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="future-work">Future Work<a href="#future-work" class="hash-link" aria-label="Direct link to Future Work" title="Direct link to Future Work">​</a></h3><p>Seamless could be improved to support more use cases and offer more functionality. Some features we would like to explore are:</p><ul><li>Additional microservice-specific testing options.</li><li>Expanding deployment options beyond ECS Fargate.</li><li>Supporting microservices not built using Node.js.</li><li>Caching dependencies between pipeline executions.</li></ul><p>Thank you for taking the time to read our case study!</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="references">References<a href="#references" class="hash-link" aria-label="Direct link to References" title="Direct link to References">​</a></h2><div class="footnotes"><hr><ol><li id="fn-1"><a href="https://www.cmswire.com/information-management/version-control-systems-the-link-between-development-and-deployment/" target="_blank" rel="noopener noreferrer">https://www.cmswire.com/information-management/version-control-systems-the-link-between-development-and-deployment/</a><a href="#fnref-1" class="footnote-backref">↩</a></li><li id="fn-2"><a href="https://medium.com/driven-by-code/the-journey-to-ci-cd-b1872927c36b" target="_blank" rel="noopener noreferrer">https://medium.com/driven-by-code/the-journey-to-ci-cd-b1872927c36b</a><a href="#fnref-2" class="footnote-backref">↩</a></li><li id="fn-3"><a href="https://hosteddocs.ittoolbox.com/RAW14335USEN-1.pdf" target="_blank" rel="noopener noreferrer">https://hosteddocs.ittoolbox.com/RAW14335USEN-1.pdf</a><a href="#fnref-3" class="footnote-backref">↩</a></li><li id="fn-4"><a href="https://hosteddocs.ittoolbox.com/RAW14335USEN-1.pdf" target="_blank" rel="noopener noreferrer">https://hosteddocs.ittoolbox.com/RAW14335USEN-1.pdf</a><a href="#fnref-4" class="footnote-backref">↩</a></li><li id="fn-5"><a href="https://medium.com/driven-by-code/the-journey-to-ci-cd-b1872927c36b" target="_blank" rel="noopener noreferrer">https://medium.com/driven-by-code/the-journey-to-ci-cd-b1872927c36b</a><a href="#fnref-5" class="footnote-backref">↩</a></li><li id="fn-6"><a href="https://blog.technologent.com/avoid-these-5-ci/cd-pipeline-challenges" target="_blank" rel="noopener noreferrer">https://blog.technologent.com/avoid-these-5-ci/cd-pipeline-challenges</a><a href="#fnref-6" class="footnote-backref">↩</a></li><li id="fn-7"><a href="https://semaphoreci.com/blog/cicd-pipeline" target="_blank" rel="noopener noreferrer">https://semaphoreci.com/blog/cicd-pipeline</a><a href="#fnref-7" class="footnote-backref">↩</a></li><li id="fn-8"><a href="https://services.google.com/fh/files/misc/2022_state_of_devops_report.pdf" target="_blank" rel="noopener noreferrer">https://services.google.com/fh/files/misc/2022_state_of_devops_report.pdf</a><a href="#fnref-8" class="footnote-backref">↩</a></li><li id="fn-9"><a href="https://semaphoreci.com/blog/cicd-pipeline" target="_blank" rel="noopener noreferrer">https://semaphoreci.com/blog/cicd-pipeline</a><a href="#fnref-9" class="footnote-backref">↩</a></li><li id="fn-10"><a href="https://learn.microsoft.com/en-us/azure/architecture/example-scenario/apps/devops-dotnet-baseline" target="_blank" rel="noopener noreferrer">https://learn.microsoft.com/en-us/azure/architecture/example-scenario/apps/devops-dotnet-baseline</a><a href="#fnref-10" class="footnote-backref">↩</a></li><li id="fn-11"><a href="https://www.split.io/wp-content/uploads/2022/07/OReilly_Continuous_Delivery.pdf&amp;sa=D&amp;source=docs&amp;ust=1680661643888770&amp;usg=AOvVaw32qMoYJHHq2EAyhO-rJgav" target="_blank" rel="noopener noreferrer">https://www.split.io/wp-content/uploads/2022/07/OReilly_Continuous_Delivery.pdf&amp;sa=D&amp;source=docs&amp;ust=1680661643888770&amp;usg=AOvVaw32qMoYJHHq2EAyhO-rJgav</a><a href="#fnref-11" class="footnote-backref">↩</a></li><li id="fn-12"><a href="https://www.atlassian.com/microservices/microservices-architecture/microservices-vs-monolith" target="_blank" rel="noopener noreferrer">https://www.atlassian.com/microservices/microservices-architecture/microservices-vs-monolith</a><a href="#fnref-12" class="footnote-backref">↩</a></li><li id="fn-13"><a href="https://www.ibm.com/topics/microservices" target="_blank" rel="noopener noreferrer">https://www.ibm.com/topics/microservices</a><a href="#fnref-13" class="footnote-backref">↩</a></li><li id="fn-14"><a href="https://www.youtube.com/watch?v=TAP8vVbsBXQ&amp;t=2490s" target="_blank" rel="noopener noreferrer">https://www.youtube.com/watch?v=TAP8vVbsBXQ&amp;t=2490s</a><a href="#fnref-14" class="footnote-backref">↩</a></li><li id="fn-15"><a href="https://techbeacon.com/enterprise-it/microservices-containers-operations-guess-whos-responsible-now" target="_blank" rel="noopener noreferrer">https://techbeacon.com/enterprise-it/microservices-containers-operations-guess-whos-responsible-now</a><a href="#fnref-15" class="footnote-backref">↩</a></li><li id="fn-16"><a href="https://www.youtube.com/watch?v=TAP8vVbsBXQ&amp;t=2490s" target="_blank" rel="noopener noreferrer">https://www.youtube.com/watch?v=TAP8vVbsBXQ&amp;t=2490s</a><a href="#fnref-16" class="footnote-backref">↩</a></li><li id="fn-17"><a href="https://en.wikipedia.org/wiki/Don&#x27;t_repeat_yourself" target="_blank" rel="noopener noreferrer">https://en.wikipedia.org/wiki/Don&#x27;t_repeat_yourself</a><a href="#fnref-17" class="footnote-backref">↩</a></li><li id="fn-18"><a href="https://www.youtube.com/watch?v=TAP8vVbsBXQ&amp;t=2490s" target="_blank" rel="noopener noreferrer">https://www.youtube.com/watch?v=TAP8vVbsBXQ&amp;t=2490s</a><a href="#fnref-18" class="footnote-backref">↩</a></li><li id="fn-19"><a href="https://medium.com/containers-101/ci-cd-pipelines-for-microservices-ea33fb48dae0" target="_blank" rel="noopener noreferrer">https://medium.com/containers-101/ci-cd-pipelines-for-microservices-ea33fb48dae0</a><a href="#fnref-19" class="footnote-backref">↩</a></li><li id="fn-20"><a href="https://martinfowler.com/articles/microservice-testing/" target="_blank" rel="noopener noreferrer">https://martinfowler.com/articles/microservice-testing/</a><a href="#fnref-20" class="footnote-backref">↩</a></li><li id="fn-21"><a href="https://martinfowler.com/articles/microservice-testing/#testing-integration-introduction" target="_blank" rel="noopener noreferrer">https://martinfowler.com/articles/microservice-testing/#testing-integration-introduction</a><a href="#fnref-21" class="footnote-backref">↩</a></li><li id="fn-22"><a href="https://plugins.jenkins.io/" target="_blank" rel="noopener noreferrer">https://plugins.jenkins.io/</a><a href="#fnref-22" class="footnote-backref">↩</a></li><li id="fn-23"><a href="https://www.nimblework.com/blog/tekton-reusable-pipelines/&amp;sa=D&amp;source=docs&amp;ust=1680661643881597&amp;usg=AOvVaw1UMq2KRT4LCJBSBu_MibY-" target="_blank" rel="noopener noreferrer">https://www.nimblework.com/blog/tekton-reusable-pipelines/&amp;sa=D&amp;source=docs&amp;ust=1680661643881597&amp;usg=AOvVaw1UMq2KRT4LCJBSBu_MibY-</a><a href="#fnref-23" class="footnote-backref">↩</a></li><li id="fn-24"><a href="https://www.codecapers.com.au/microservices-for-startups-1/" target="_blank" rel="noopener noreferrer">https://www.codecapers.com.au/microservices-for-startups-1/</a><a href="#fnref-24" class="footnote-backref">↩</a></li><li id="fn-25"><a href="https://www.perceptionsystem.com/blog/startups-with-micro-services-architecture/" target="_blank" rel="noopener noreferrer">https://www.perceptionsystem.com/blog/startups-with-micro-services-architecture/</a><a href="#fnref-25" class="footnote-backref">↩</a></li><li id="fn-26"><a href="https://www.codecapers.com.au/microservices-for-startups-1/" target="_blank" rel="noopener noreferrer">https://www.codecapers.com.au/microservices-for-startups-1/</a><a href="#fnref-26" class="footnote-backref">↩</a></li><li id="fn-27"><a href="https://codefresh.io/docs/docs/pipelines/introduction-to-codefresh-pipelines/" target="_blank" rel="noopener noreferrer">https://codefresh.io/docs/docs/pipelines/introduction-to-codefresh-pipelines/</a><a href="#fnref-27" class="footnote-backref">↩</a></li></ol></div></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#1-introduction" class="table-of-contents__link toc-highlight">1. Introduction</a></li><li><a href="#2-evolution-of-deployment-processes" class="table-of-contents__link toc-highlight">2. Evolution of Deployment Processes</a></li><li><a href="#3-cicd-pipelines" class="table-of-contents__link toc-highlight">3. CI/CD Pipelines</a></li><li><a href="#4-balancing-safety-and-velocity" class="table-of-contents__link toc-highlight">4. Balancing Safety and Velocity</a></li><li><a href="#5-cicd-for-monoliths-and-microservices" class="table-of-contents__link toc-highlight">5. CI/CD for Monoliths and Microservices</a></li><li><a href="#6-cicd-challenges-with-microservices" class="table-of-contents__link toc-highlight">6. CI/CD Challenges with Microservices</a></li><li><a href="#7-manually-building-a-cicd-pipeline-for-microservices" class="table-of-contents__link toc-highlight">7. Manually Building a CI/CD Pipeline for Microservices</a></li><li><a href="#8-existing-solutions" class="table-of-contents__link toc-highlight">8. Existing Solutions</a></li><li><a href="#9-introducing-seamless" class="table-of-contents__link toc-highlight">9. Introducing Seamless</a></li><li><a href="#10-architecture-overview" class="table-of-contents__link toc-highlight">10. Architecture Overview</a></li><li><a href="#11-building-the-core-pipeline-functionality" class="table-of-contents__link toc-highlight">11. Building the Core Pipeline Functionality</a></li><li><a href="#12-improving-core-functionality" class="table-of-contents__link toc-highlight">12. Improving Core Functionality</a></li><li><a href="#13-beyond-the-core-pipeline" class="table-of-contents__link toc-highlight">13. Beyond the Core Pipeline</a></li><li><a href="#14-conclusion--future-work" class="table-of-contents__link toc-highlight">14. Conclusion &amp; Future Work</a></li><li><a href="#references" class="table-of-contents__link toc-highlight">References</a></li></ul></div></div></div></div></main></div></div></div>
<script src="/assets/js/runtime~main.232210d9.js"></script>
<script src="/assets/js/main.ae001262.js"></script>
</body>
</html>